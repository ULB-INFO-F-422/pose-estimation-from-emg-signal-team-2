{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895a75fb",
   "metadata": {},
   "source": [
    "# INFO-f422: ML Project\n",
    "\n",
    "authors:\n",
    "+ 1 \n",
    "+ 2\n",
    "+ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcc5fc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17578f83-f52e-47ee-9d73-b33d910722dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fe755",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ae6158-83fc-4039-ad35-4168b9fed8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "\n",
    "X_g_train = np.load(\"../guided/guided_dataset_X.npy\")\n",
    "y_g_train = np.load(\"../guided/guided_dataset_y.npy\")\n",
    "X_g_test = np.load(\"../guided/guided_testset_X.npy\")\n",
    "\n",
    "X_f_train = np.load(\"../freemoves/freemoves_dataset_X.npy\")\n",
    "y_f_train = np.load(\"../freemoves/freemoves_dataset_y.npy\")\n",
    "X_f_test = np.load(\"../freemoves/freemoves_testset_X.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d74e88-bad4-4a00-9cdf-b5b5b1f6cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided:\n",
      "X_g_train (5, 8, 230000) / y_g_train(5, 51, 230000) / X_g_test(5, 332, 8, 500)\n",
      "\n",
      "Free moves:\n",
      "X_f_train(5, 8, 270000) / y_f_train(5, 51, 270000) / X_f_test(5, 308, 8, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Guided:\")\n",
    "print(f\"X_g_train {X_g_train.shape} / y_g_train{y_g_train.shape} / X_g_test{X_g_test.shape}\\n\")\n",
    "print(\"Free moves:\")\n",
    "print(f\"X_f_train{X_f_train.shape} / y_f_train{y_f_train.shape} / X_f_test{X_f_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29437e-9e32-45e1-a305-0bfad39af254",
   "metadata": {},
   "source": [
    "### 1) Signal filtering\n",
    "\n",
    "TODO: data exploration to take informed decision on filter (type of noise,....) to use and on filter parametres (no magic number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4331fabb-bc67-49c5-8d18-9572b5dc3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfiltfilt, firwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bdf832f-16c7-4dbf-b0cc-43fc14aa64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyq  = 1024 / 2\n",
    "low  = 20  / nyq\n",
    "high = 450 / nyq\n",
    "\n",
    "sos = butter(4,[low,high], btype='band', output= 'sos')\n",
    "\n",
    "for sess in range(X_g_train.shape[0]):\n",
    "    for elec in range(X_g_train.shape[1]):\n",
    "        # Application of the filtrage for x\n",
    "        X_g_train[sess, elec, :] = sosfiltfilt(sos, X_g_train[sess, elec, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1dfcb3-48a7-4df1-80ec-79e5fd3bd630",
   "metadata": {},
   "source": [
    "### 2) Dataset preparation\n",
    "\n",
    "At the beginning, we implemented a naive function that loops for each windows needed. \n",
    "\n",
    "This version work but:\n",
    "- Only when the step size can divides the total number of samples.  \n",
    "- Copies every window into a new array, incurring  CPU overhead and unnecessary memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c97d3d-aa09-418c-bafd-3d7be401f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(data, overlap=0.5, size=500):\n",
    "    Data = []\n",
    "    step = int(size * (1 - overlap))\n",
    "    n = (data.shape[2] - size) // step + 1\n",
    "    fin = n * step\n",
    "    \n",
    "    for start in range(0, fin, step):\n",
    "        end = start + size\n",
    "        W = data[... , start:end]\n",
    "        Data.append(W)\n",
    "        \n",
    "    Data = np.array(Data)\n",
    "    Data = Data.transpose(1, 0, 2, 3)\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29750bdf-f261-4fd6-84b0-d4dc3bd2aa55",
   "metadata": {},
   "source": [
    "But after some research, we decided to use the sliding_window_view function from the Numpy library for several reasons:\n",
    "\n",
    "+ Fast vectorized numpy operations, compiled c-code (no python overhead, interpreter).\n",
    "\n",
    "+ sliding_window_view function returns a view, no copy.\n",
    "\n",
    "+ The function simplifies the implementation by automating window creation and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74676a2-d393-4e44-98ce-48190ed197a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided windowed:\n",
      "X_g_train_wdw (5, 919, 8, 500) / y_g_train_wdw(5, 919, 51) / X_g_test(5, 332, 8, 500)\n"
     ]
    }
   ],
   "source": [
    "def create_overlap_windows(x, y, window_size, overlap, axis):\n",
    "\n",
    "    step = int(window_size * (1 - overlap))\n",
    "\n",
    "    # sliding_windows_view Generate all possible windows with the corresponding step, that not what we want.\n",
    "    x_w = sliding_window_view(x,window_size,axis)\n",
    "    y_w = sliding_window_view(y,window_size,axis)\n",
    "\n",
    "    # only keep windows where the step is a multiple of our step \n",
    "    x_w = x_w[:,:,::step,:]\n",
    "    y_w = y_w[:,:,::step,:]\n",
    "\n",
    "    # We transpose the axes windows and electrode/signal \n",
    "    x_w = x_w.transpose(0, 2, 1, 3)     #  (session, window, electrode, time) and not  (session, electrode, window, time) TODO??\n",
    "    y_w = y_w.transpose(0, 2, 1, 3)     # (session, window, signals, time)\n",
    "\n",
    "    # Finaly, we keep only the last hand position (targets) for y, because for this project\n",
    "    # we need to predict, for each window in x, the final hand position in the\n",
    "    # same windows in the dataset y\n",
    "    y_w = y_w[..., -1]  # (sessions, windows, targets)\n",
    "\n",
    "    return x_w, y_w\n",
    "\n",
    "\n",
    "X_g_train_wdw, y_g_train_wdw = create_overlap_windows(X_g_train, y_g_train, window_size=500, overlap=0.5, axis=2)\n",
    "# !! windowed data is a view --> share original data memory (modify one, modify both)\n",
    "\n",
    "print(\"Guided windowed:\")\n",
    "print(f\"X_g_train_wdw {X_g_train_wdw.shape} / y_g_train_wdw{y_g_train_wdw.shape} / X_g_test{X_g_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5557ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_windows_tests(x, y):\n",
    "    # (maybe automate tests given windowsize and overlap and consider internal frag (shoudl be discarded)\n",
    "    \n",
    "    x_w, y_w = create_overlap_windows(x, y, window_size=500, overlap=0.5, axis=2)    \n",
    "    \n",
    "    assert np.array_equal(x_w[0, 0, 0, :10], x[0, 0, :10]) # (sess 0) first 10 of electrode 0 in window 0\n",
    "    assert np.array_equal(x_w[0, 1, 0, :10], x[0, 0, 250:260]) # (sess 0) first 10 of electrode 0 in window 1\n",
    "    assert np.array_equal(x_w[0, 1, 4, :10], x[0, 4, 250:260]) # (sess 0) first 10 of electrode 4 in window 1\n",
    "    assert np.array_equal(x_w[0, 918, 0, -10:], x[0, 0, 229990:230000]) # (sess 0) last 10 of electrode 0 in last window (918) - (perfect fit!)\n",
    "\n",
    "quick_windows_tests(X_g_train, y_g_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa6666-9c5a-422c-8c26-79b8f6594316",
   "metadata": {},
   "source": [
    "#### 3) Cross validation strategy\n",
    "\n",
    "For this question, we have thought about various methods of cross validation. First, our data are continous because it's a signal, so preserving temporal structure is important. We canâ€™t use a method of cross validation which randomly shuffles our windows. \n",
    "\n",
    "We also need to prevents data leaking so we can't use a methode who use the windows of one session for training AND validation because we have overlapping data in each session, two windows in the same session can share the same datas, and if these two windows are in train and validation, it will lead to data leakage and overly optimistic performance (data in the train set will also be in the validation set). \n",
    "\n",
    "So it's naturally that we have chosen the \"Leave One Group Out\" method, this method will use each session as the validation set once and the other for training. We completly prevent data leakage because each session is indepandent from the other, and we reduce the bias because each session will be used for validation.\n",
    "\n",
    "In our case, \"LOGO\" and \"GroupKFold(5)\" produce the same splits, but we choose \"LOGO\" because it's more explicit, readers will immediatly see that we use one session for validation each time while \"GroupKFold\" need to have 5 in parameter to do the same thong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d586a98-56d4-4372-a33f-01ba5ec537cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups(4595,)\n",
      "\n",
      "Guided windowed flattened:\n",
      "X_g_train_wdw_flat(4595, 4000) / y_g_train_wdw_flat(4595, 51)\n"
     ]
    }
   ],
   "source": [
    "x_shape = X_g_train_wdw.shape\n",
    "y_shape = y_g_train_wdw.shape\n",
    "\n",
    "groups = np.repeat(np.arange(1,x_shape[0]+1),x_shape[1] ) # 111 (919 times), 222 (919 times), ...\n",
    "print(f\"groups{groups.shape}\\n\")\n",
    "\n",
    "# We need to flatten the dataset x and y because the function logo (and latter \"croos_val_score\")\n",
    "# want all the data in a 2d list, we will know have  the dataset X for exemple.\n",
    "# [4595, 4000] and not [5,919,8,500], 4595 is the multiplication of 5 and 919 (3500 = 8*500), and y \n",
    "# [4595,51] and not [5,919,51].\n",
    "# Now all the windows are store in a list and the \"groups\" list above allow the function \n",
    "# logo to know at wich session each windows belong\n",
    "# The windows 3 for example (x_windows_flat[2]) belong to the sessions groups[2] = 1\n",
    "X_g_train_wdw_flat = X_g_train_wdw.reshape(x_shape[0] * x_shape[1], x_shape[2] * x_shape[3])\n",
    "y_g_train_wdw_flat = y_g_train_wdw.reshape(y_shape[0] * y_shape[1], y_shape[2])\n",
    "\n",
    "print(\"Guided windowed flattened:\")\n",
    "print(f\"X_g_train_wdw_flat{X_g_train_wdw_flat.shape} / y_g_train_wdw_flat{y_g_train_wdw_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92449bff-754d-4a5a-b2ca-d88385116328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07e1243c-045c-436b-85b1-725a43ead35f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.785e+03, tolerance: 4.776e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.965e+03, tolerance: 4.492e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.740e+03, tolerance: 4.265e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e+03, tolerance: 4.499e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.302e+03, tolerance: 4.404e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.188e+02, tolerance: 8.546e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+02, tolerance: 7.985e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+02, tolerance: 8.217e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e+02, tolerance: 8.114e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+02, tolerance: 7.089e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.688e+04, tolerance: 4.189e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.457e+04, tolerance: 4.037e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.205e+04, tolerance: 4.466e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.924e+04, tolerance: 4.204e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.809e+04, tolerance: 4.038e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.592e-01, tolerance: 1.132e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.005e-01, tolerance: 1.127e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.222e-01, tolerance: 1.192e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+00, tolerance: 1.128e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.758e-01, tolerance: 1.022e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+04, tolerance: 9.544e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+04, tolerance: 9.268e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e+04, tolerance: 9.687e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+04, tolerance: 9.434e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+04, tolerance: 9.160e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.737e+03, tolerance: 2.501e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.931e+03, tolerance: 2.427e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+03, tolerance: 2.535e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e+03, tolerance: 2.472e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+03, tolerance: 2.407e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.133e+00, tolerance: 2.192e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.652e+00, tolerance: 2.080e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+00, tolerance: 2.209e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.721e+00, tolerance: 2.156e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e+00, tolerance: 2.252e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+05, tolerance: 5.803e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+05, tolerance: 5.580e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+05, tolerance: 5.686e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+05, tolerance: 5.886e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+05, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.673e+02, tolerance: 1.138e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e+02, tolerance: 1.142e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.865e+02, tolerance: 1.171e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e-01, tolerance: 1.052e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e+02, tolerance: 1.115e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e+02, tolerance: 1.155e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.881e-01, tolerance: 1.051e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.326e-01, tolerance: 1.104e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.715e-01, tolerance: 1.093e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.525e+05, tolerance: 1.931e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.519e+05, tolerance: 1.938e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.657e+05, tolerance: 1.997e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.345e-01, tolerance: 8.278e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.626e+05, tolerance: 1.966e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.545e+05, tolerance: 1.874e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.870e-01, tolerance: 8.988e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.834e+02, tolerance: 1.955e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.125e-01, tolerance: 8.563e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e-01, tolerance: 8.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.923e-01, tolerance: 8.427e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+03, tolerance: 2.163e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.378e+02, tolerance: 2.206e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+03, tolerance: 2.081e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+05, tolerance: 1.121e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+03, tolerance: 1.889e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.255e+05, tolerance: 1.193e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+05, tolerance: 1.141e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.235e+05, tolerance: 1.159e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.320e+05, tolerance: 1.188e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.534e+05, tolerance: 4.759e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.416e+05, tolerance: 4.854e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.657e+05, tolerance: 4.853e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.663e+05, tolerance: 4.810e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.992e+05, tolerance: 4.898e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.874e-02, tolerance: 6.222e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e-01, tolerance: 6.130e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.154e+05, tolerance: 2.145e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.378e+05, tolerance: 2.249e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.331e+05, tolerance: 2.284e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.273e+05, tolerance: 2.176e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.333e+05, tolerance: 2.142e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e+02, tolerance: 8.295e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.271e+02, tolerance: 8.483e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.742e+02, tolerance: 9.112e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+02, tolerance: 9.297e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+02, tolerance: 8.659e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+05, tolerance: 1.293e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.633e+05, tolerance: 1.347e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+05, tolerance: 1.378e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+05, tolerance: 1.390e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.539e+05, tolerance: 1.336e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.197e+05, tolerance: 5.200e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.613e+05, tolerance: 5.276e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.387e+05, tolerance: 5.241e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.197e+02, tolerance: 1.033e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.232e+05, tolerance: 5.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.627e+05, tolerance: 5.309e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.199e+02, tolerance: 1.041e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+02, tolerance: 1.060e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+01, tolerance: 3.974e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+02, tolerance: 1.021e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+01, tolerance: 4.036e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+02, tolerance: 1.023e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+01, tolerance: 4.218e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.196e+05, tolerance: 1.644e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+01, tolerance: 3.764e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+01, tolerance: 3.893e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.361e+05, tolerance: 1.661e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.397e+05, tolerance: 1.708e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.205e+05, tolerance: 1.602e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+02, tolerance: 1.021e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.127e+05, tolerance: 1.623e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.399e+02, tolerance: 1.073e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.539e+05, tolerance: 1.921e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+02, tolerance: 1.123e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e+02, tolerance: 9.629e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.816e+05, tolerance: 1.987e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.580e+02, tolerance: 1.100e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.681e+05, tolerance: 1.965e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.749e+05, tolerance: 1.980e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e+00, tolerance: 1.706e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.639e+05, tolerance: 1.958e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.462e-01, tolerance: 1.713e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+06, tolerance: 6.286e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.252e-01, tolerance: 1.715e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.732e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e-01, tolerance: 1.697e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+06, tolerance: 6.315e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.738e+01, tolerance: 5.849e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+06, tolerance: 6.333e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+06, tolerance: 6.463e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.817e+01, tolerance: 5.981e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.249e+00, tolerance: 2.773e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+06, tolerance: 6.268e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.284e+01, tolerance: 6.033e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+02, tolerance: 6.000e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+00, tolerance: 2.816e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.868e+01, tolerance: 5.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.131e+05, tolerance: 1.582e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+01, tolerance: 2.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.759e+00, tolerance: 2.672e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.607e+00, tolerance: 2.735e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.286e+05, tolerance: 1.616e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.223e+05, tolerance: 1.647e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+05, tolerance: 1.591e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.519e+00, tolerance: 3.038e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.116e+05, tolerance: 1.587e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.343e+03, tolerance: 6.145e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.204e+00, tolerance: 3.297e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.959e+00, tolerance: 3.204e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+04, tolerance: 6.584e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.357e+05, tolerance: 2.356e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.430e+00, tolerance: 3.157e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.957e+03, tolerance: 6.703e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.369e+00, tolerance: 2.364e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.923e+05, tolerance: 2.563e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.952e+03, tolerance: 6.573e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.465e+05, tolerance: 2.427e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+01, tolerance: 5.220e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+01, tolerance: 3.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.925e+00, tolerance: 2.403e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.458e+05, tolerance: 2.453e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+01, tolerance: 2.395e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.358e+05, tolerance: 4.605e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+04, tolerance: 6.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.518e+01, tolerance: 5.220e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.474e+00, tolerance: 2.336e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.873e+01, tolerance: 5.179e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+00, tolerance: 2.089e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.060e+01, tolerance: 5.125e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.624e+05, tolerance: 4.627e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.766e+05, tolerance: 2.565e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.304e+05, tolerance: 4.602e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+00, tolerance: 2.064e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+01, tolerance: 2.404e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.212e+05, tolerance: 4.521e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.389e+00, tolerance: 2.090e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.812e+05, tolerance: 1.377e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.367e+01, tolerance: 5.203e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+00, tolerance: 2.079e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.859e+05, tolerance: 1.367e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.301e+05, tolerance: 4.615e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.897e+05, tolerance: 1.402e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e+00, tolerance: 2.039e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+05, tolerance: 1.364e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for each folder: [19.80889373 20.70289974 23.42573968 20.45592827 21.90544978]\n",
      "RMSE mean: 21.259782241197765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.782e+05, tolerance: 1.351e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "lasso_model = Lasso(max_iter=10) # If the iteration is higher, it take to much time, even on collab \n",
    "ridge_model = Ridge()\n",
    "\n",
    "rmse_scorer = make_scorer(\n",
    "    lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    greater_is_better=False  # Score near 0 is better \n",
    ")\n",
    "\n",
    "def cross_validation_with_scores(X,Y,groups,model,cv,scoring):\n",
    "    # The cross_val_score function by sklearn will execute our cv and return a tab \n",
    "    neg_rmse_scores = cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        Y,\n",
    "        groups=groups,\n",
    "        cv=cv,\n",
    "        scoring=rmse_scorer,\n",
    "        n_jobs=-1 # Use all cores \n",
    "    )\n",
    "    \n",
    "    # Conversion of negatifs scores into positifs (convention of sklearn)\n",
    "    rmse_scores = -neg_rmse_scores  \n",
    "    print(\"RMSE for each folder:\", rmse_scores)\n",
    "    print(\"RMSE mean:\", rmse_scores.mean())\n",
    "\n",
    "cross_validation_with_scores(X_g_train_wdw_flat,y_g_train_wdw_flat,groups,lasso_model,logo,rmse_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384848b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 0 target info:\n",
      "  min = -108.68231864942676\n",
      "  max = 44.76897408739836\n",
      "  mean = -5.73247691191569\n"
     ]
    }
   ],
   "source": [
    "# rmse context\n",
    "sess = 0\n",
    "y_max = np.max(y_g_train_wdw[sess])\n",
    "y_min = np.min(y_g_train_wdw[sess])\n",
    "y_mean = np.mean(y_g_train_wdw[sess])\n",
    "\n",
    "print(f\"Session {sess} target info:\\n  min = {y_min}\\n  max = {y_max}\\n  mean = {y_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecd17ef4-108a-480b-aba8-33de84479a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "   train groups: [2 3 4 5]\n",
      "   test groups: [1]\n",
      "Fold 1\n",
      "   train groups: [1 3 4 5]\n",
      "   test groups: [2]\n",
      "Fold 2\n",
      "   train groups: [1 2 4 5]\n",
      "   test groups: [3]\n",
      "Fold 3\n",
      "   train groups: [1 2 3 5]\n",
      "   test groups: [4]\n",
      "Fold 4\n",
      "   train groups: [1 2 3 4]\n",
      "   test groups: [5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (train_index, test_index) in enumerate(logo.split(X_g_train_wdw_flat, y_g_train_wdw_flat, groups)):\n",
    "    print(f\"Fold {i}\")\n",
    "    print(f\"   train groups: {np.unique(groups[train_index])}\")\n",
    "    print(f\"   test groups: {np.unique(groups[test_index])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3b954-0157-4eae-a02d-355a20329d9a",
   "metadata": {},
   "source": [
    "#### 5) More sophisticated approach\n",
    "\n",
    "For this question, we decided to implement the two approaches in order to have a better understanding and more methods to compare.\n",
    "\n",
    "We started with the covariance approch, following the steps in section 3.2:\n",
    "\n",
    "- We first calculate the covaraince of each windows with the PyRiemmann Covariances class, which expects a 3d array, so we need to reshape it into the form (windows,electrode,time). After using this class, we obtain an array of 8Ã—8 covariance matrices (SPD_tab) for each window.\n",
    "\n",
    "- Next, we map each SPD matrix into their tangent space using the TangentSpace class. This projection transforms our SPD matrices into Euclidean vectors. Thanks to this, our dataset becomes 2D again, and we can directly use a traditional regression algorithms and sklearn function.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ffd5b0f-b9dc-406e-a930-9ec1ba230d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyriemann\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.pipeline     import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4668e27-97cc-4c58-b39f-1d67dcbb7ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.752e+03, tolerance: 4.189e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.308e+03, tolerance: 5.803e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.626e+04, tolerance: 1.931e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.676e+02, tolerance: 1.121e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.506e+04, tolerance: 4.759e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+04, tolerance: 2.145e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e+04, tolerance: 1.293e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+05, tolerance: 5.200e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+04, tolerance: 1.644e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.216e+04, tolerance: 1.921e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e+05, tolerance: 6.286e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+04, tolerance: 1.582e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.473e+03, tolerance: 4.204e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e+03, tolerance: 2.356e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.688e+04, tolerance: 4.605e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+03, tolerance: 1.377e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e+03, tolerance: 5.580e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.335e+04, tolerance: 1.938e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.768e+03, tolerance: 1.159e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.411e+04, tolerance: 4.810e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e+04, tolerance: 2.176e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.347e+03, tolerance: 1.336e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.540e+05, tolerance: 5.174e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+04, tolerance: 1.623e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.834e+04, tolerance: 1.958e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.386e+05, tolerance: 6.268e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.437e+03, tolerance: 1.587e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.188e+03, tolerance: 2.453e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.421e+03, tolerance: 4.521e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+03, tolerance: 1.364e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.961e+02, tolerance: 4.037e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.785e+02, tolerance: 5.886e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.182e+04, tolerance: 1.966e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.779e+03, tolerance: 1.141e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.126e+04, tolerance: 4.853e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+04, tolerance: 2.249e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.139e+03, tolerance: 1.347e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+05, tolerance: 5.276e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e+04, tolerance: 1.661e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.892e+04, tolerance: 1.987e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+05, tolerance: 6.315e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+04, tolerance: 1.616e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.630e+03, tolerance: 2.563e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.497e+04, tolerance: 4.627e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+03, tolerance: 1.367e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+03, tolerance: 4.466e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+03, tolerance: 5.686e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.113e+04, tolerance: 1.997e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.559e+03, tolerance: 1.193e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.969e+05, tolerance: 4.854e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+04, tolerance: 2.284e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+04, tolerance: 1.378e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.723e+04, tolerance: 5.241e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.412e+03, tolerance: 1.708e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.661e+04, tolerance: 1.965e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.130e+05, tolerance: 6.333e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e+04, tolerance: 1.647e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.441e+03, tolerance: 2.427e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.246e+04, tolerance: 4.602e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.728e+03, tolerance: 4.038e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.793e+02, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e+04, tolerance: 1.874e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e+03, tolerance: 1.188e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.492e+04, tolerance: 4.898e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+04, tolerance: 2.142e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+04, tolerance: 1.390e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+05, tolerance: 5.309e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.462e+04, tolerance: 1.602e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.813e+04, tolerance: 1.980e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e+05, tolerance: 6.463e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+04, tolerance: 1.591e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.099e+00, tolerance: 6.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+03, tolerance: 2.565e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.475e+03, tolerance: 4.615e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e+03, tolerance: 1.351e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for each folder: [8.7824265  8.28236659 8.21322829 7.31930597 8.34535656]\n"
     ]
    }
   ],
   "source": [
    "# Covariances method\n",
    "\n",
    "\n",
    "# Reshape the flattten dataset\n",
    "X_g_train_reshape = X_g_train_wdw_flat.reshape(4595,8,500)\n",
    "\n",
    "'''\n",
    "covariance = Covariances(estimator='oas')\n",
    "SPD_tab = covariance.fit_transform(X_g_train_reshape) \n",
    "# print(SPD_tab.shape) # (4595,8,8)\n",
    "ts = TangentSpace()\n",
    "tangent_tab = ts.fit_transform(SPD_tab)\n",
    "# print(tangent_tab.shape) # (4595,36) Now that we have a 2d tab, we can use traditional regression algorithms\n",
    "'''\n",
    "\n",
    "pipe_cov = Pipeline([\n",
    "    ('cov',    Covariances(estimator='oas')),   # Covariances matrices of each windows\n",
    "    ('ts',     TangentSpace()),                 # This projection will transform our SPD matrices into euclidean vector\n",
    "    ('scale', StandardScaler()),          # Standardize each feature (mean =0, std =1) \n",
    "    ('lasso',  lasso_model)               # Lasso model \n",
    "])\n",
    "\n",
    "# Now we juste need to use the cv function we build above \n",
    "cross_validation_with_scores(X_g_train_reshape,y_g_train_wdw_flat,groups,pipe_cov,logo,rmse_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f83a5-45be-463c-93c1-254dec71ef8e",
   "metadata": {},
   "source": [
    "For the neural network approch, we have done:\n",
    "\n",
    "##### Simple model\n",
    "We started by a simple model composed of 3 linear layers.\n",
    "\n",
    "To evaluate it, we used Skorch, which lets us plug a PyTorch nn.Module into a sklearn function.\n",
    "Thanks to Skorch, we could reuse our existing cross_validation_with_scores() function.\n",
    "\n",
    "The rmse mean was 17.03, which beat the vanilla lasso model but not the covriance matrices lasso. We analyzed the value of the training loss and validation loss for each epoch and we saw that the model is underfitting.\n",
    "So we decide to complexify it.\n",
    "\n",
    "##### Model complexity\n",
    "\n",
    "We upgraded to a small CNN with three 1D convolutional layers because the dataset has to much datas for an nn classique and to automatically learn local temporal patterns in the EMG signal. \n",
    "\n",
    "After each convolutional layer:\n",
    "\n",
    "We normalize our data to stabilize and speed up training.\n",
    "\n",
    "We introduce a simple Relu activation so the network can learn more complex features.\n",
    "\n",
    "We â€œcutâ€ the time dimension in half, keeping only the strongest responses and reducing data size.\n",
    "\n",
    "Once the three convolutional blocks are done, we flatten the output tensor and pass it into a two layer head, to convert these extracted features into the 51 joint-angle predictions\n",
    "\n",
    "##### Early stopping and LR scheduling\n",
    "\n",
    "We added two Skorch callbacks:\n",
    "\n",
    "-EarlyStopping to stop the training when no improvement is seen for 5 epochs.\n",
    "\n",
    "-LRScheduler to cut the learning rate by half when the validation loss stalls 3 epochs consecutives.\n",
    "\n",
    "This combination prevents wasted epochs once the model converges and refines the learning rate to squeeze out extra gains.\n",
    "\n",
    "##### Batch size reduction\n",
    "\n",
    "We lowered the batch size from 128 to 64. Using smaller batches adds a bit of randomness to each weight update, which helps the model generalize better without altering its structure.\n",
    "\n",
    "With these three changes, the nn average RMSE dropped to ~5.07, a dramatic improvement over the initial ~17."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074777f-d8a4-4172-b732-6a425d3f0fbc",
   "metadata": {},
   "source": [
    "| Simple Model | Complex Model | Complex Model + Early Stopping & LR Scheduler | Same as #3 but Batch Size = 64 |\n",
    "|:------------:|:-------------:|:---------------------------------------------:|:-----------------------------:|\n",
    "| ![](./images/1.png) | ![](./images/2.png) | ![](./images/3.png) | ![](./images/4.png) |\n",
    "| **RMSE mean:** 17.03 | **RMSE mean:** 6.06 | **RMSE mean:** 5.89 | **RMSE mean:** 4.87 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8a70a53-6562-4aa8-b197-af063ca6a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U skorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from skorch.callbacks import LRScheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42cd60a5-d6f7-4e74-91f0-f26c7c8b7ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr      dur\n",
      "-------  ------------  ------------  ------  -------\n",
      "      1      \u001b[36m185.6069\u001b[0m      \u001b[32m109.5786\u001b[0m  0.0010  13.4515\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr      dur\n",
      "-------  ------------  ------------  ------  -------\n",
      "      1      \u001b[36m194.1085\u001b[0m      \u001b[32m112.3353\u001b[0m  0.0010  13.4936\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr      dur\n",
      "-------  ------------  ------------  ------  -------\n",
      "      1      \u001b[36m191.2136\u001b[0m      \u001b[32m117.3103\u001b[0m  0.0010  13.6682\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr      dur\n",
      "-------  ------------  ------------  ------  -------\n",
      "      1      \u001b[36m187.5042\u001b[0m      \u001b[32m112.2389\u001b[0m  0.0010  13.7561\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr      dur\n",
      "-------  ------------  ------------  ------  -------\n",
      "      1      \u001b[36m191.1444\u001b[0m      \u001b[32m134.8492\u001b[0m  0.0010  13.9960\n",
      "      2       \u001b[36m90.1612\u001b[0m       \u001b[32m72.2691\u001b[0m  0.0010  13.1424\n",
      "      2       \u001b[36m85.1040\u001b[0m       \u001b[32m77.1424\u001b[0m  0.0010  13.2312\n",
      "      2       \u001b[36m90.7391\u001b[0m      129.1507  0.0010  13.5699\n",
      "      2       \u001b[36m84.2999\u001b[0m       \u001b[32m83.8462\u001b[0m  0.0010  13.8389\n",
      "      2       \u001b[36m89.3147\u001b[0m      151.9440  0.0010  13.8580\n",
      "      3       \u001b[36m74.0279\u001b[0m       \u001b[32m65.1582\u001b[0m  0.0010  13.7871\n",
      "      3       \u001b[36m72.4031\u001b[0m       \u001b[32m67.1301\u001b[0m  0.0010  14.0513\n",
      "      3       \u001b[36m75.0125\u001b[0m       \u001b[32m94.2087\u001b[0m  0.0010  14.1496\n",
      "      3       \u001b[36m71.2861\u001b[0m       \u001b[32m67.0878\u001b[0m  0.0010  14.0721\n",
      "      3       \u001b[36m74.4862\u001b[0m       \u001b[32m81.2795\u001b[0m  0.0010  14.3042\n",
      "      4       \u001b[36m65.3186\u001b[0m       \u001b[32m60.4793\u001b[0m  0.0010  13.4839\n",
      "      4       \u001b[36m64.5558\u001b[0m       75.3292  0.0010  13.6276\n",
      "      4       \u001b[36m68.2102\u001b[0m       \u001b[32m84.6510\u001b[0m  0.0010  13.6082\n",
      "      4       \u001b[36m65.3882\u001b[0m       \u001b[32m67.0100\u001b[0m  0.0010  13.4649\n",
      "      4       \u001b[36m68.9957\u001b[0m       \u001b[32m73.6186\u001b[0m  0.0010  13.6660\n",
      "      5       \u001b[36m59.9691\u001b[0m       61.1982  0.0010  13.0040\n",
      "      5       \u001b[36m56.7954\u001b[0m       77.8836  0.0010  13.2378\n",
      "      5       \u001b[36m62.4503\u001b[0m      111.5758  0.0010  13.4635\n",
      "      5       \u001b[36m60.9106\u001b[0m       68.4779  0.0010  13.4029\n",
      "      5       \u001b[36m62.6342\u001b[0m       95.6233  0.0010  13.3557\n",
      "      6       \u001b[36m52.4980\u001b[0m       \u001b[32m54.9968\u001b[0m  0.0010  13.1946\n",
      "      6       \u001b[36m48.2891\u001b[0m       71.4431  0.0010  13.3647\n",
      "      6       \u001b[36m58.1505\u001b[0m      112.7767  0.0010  13.4363\n",
      "      6       \u001b[36m56.8690\u001b[0m       \u001b[32m64.2190\u001b[0m  0.0010  13.3981\n",
      "      6       \u001b[36m54.6907\u001b[0m      117.0114  0.0010  13.7715\n",
      "      7       \u001b[36m45.8400\u001b[0m       61.4197  0.0010  13.3656\n",
      "      7       \u001b[36m42.5815\u001b[0m       89.7443  0.0010  13.3087\n",
      "      7       \u001b[36m51.4723\u001b[0m       77.4074  0.0010  13.4642\n",
      "      7       \u001b[36m53.2533\u001b[0m      125.1917  0.0010  13.7509\n",
      "      7       \u001b[36m46.8428\u001b[0m       81.1069  0.0010  13.6889\n",
      "      8       \u001b[36m41.7097\u001b[0m       67.1530  0.0010  13.5800\n",
      "      8       \u001b[36m37.9886\u001b[0m       \u001b[32m45.0010\u001b[0m  0.0005  13.5636\n",
      "      8       \u001b[36m45.3779\u001b[0m       81.6667  0.0010  13.9609\n",
      "      8       \u001b[36m46.9597\u001b[0m       90.4491  0.0010  14.0827\n",
      "      8       \u001b[36m41.2495\u001b[0m       80.6095  0.0010  13.8995\n",
      "      9       \u001b[36m38.3962\u001b[0m       60.6594  0.0010  12.9960\n",
      "      9       \u001b[36m33.7297\u001b[0m       50.9079  0.0005  12.8719\n",
      "      9       \u001b[36m40.7860\u001b[0m       \u001b[32m44.0823\u001b[0m  0.0010  13.0512\n",
      "      9       \u001b[36m41.1764\u001b[0m       \u001b[32m64.2600\u001b[0m  0.0005  13.3146\n",
      "      9       \u001b[36m35.2866\u001b[0m       \u001b[32m53.2638\u001b[0m  0.0005  13.2485\n",
      "     10       \u001b[36m34.8530\u001b[0m       \u001b[32m46.0289\u001b[0m  0.0010  13.7304\n",
      "     10       \u001b[36m29.4467\u001b[0m       \u001b[32m44.9309\u001b[0m  0.0005  13.7659\n",
      "     10       \u001b[36m36.8915\u001b[0m       59.1342  0.0010  14.0029\n",
      "     10       \u001b[36m39.4623\u001b[0m       \u001b[32m44.6589\u001b[0m  0.0005  13.9907\n",
      "     10       \u001b[36m32.2828\u001b[0m       \u001b[32m48.8493\u001b[0m  0.0005  14.4287\n",
      "     11       \u001b[36m33.0955\u001b[0m       \u001b[32m41.2629\u001b[0m  0.0010  13.7937\n",
      "     11       \u001b[36m25.2599\u001b[0m       \u001b[32m39.8213\u001b[0m  0.0005  13.4939\n",
      "     11       \u001b[36m33.6659\u001b[0m       45.3462  0.0010  13.8781\n",
      "     11       \u001b[36m35.2983\u001b[0m       \u001b[32m37.9382\u001b[0m  0.0005  13.5885\n",
      "     11       \u001b[36m28.1506\u001b[0m       \u001b[32m43.7792\u001b[0m  0.0005  13.8425\n",
      "     12       \u001b[36m30.9074\u001b[0m       42.4331  0.0010  13.3670\n",
      "     12       \u001b[36m20.6230\u001b[0m       \u001b[32m38.8556\u001b[0m  0.0005  13.6561\n",
      "     12       \u001b[36m29.5075\u001b[0m       63.4440  0.0010  13.6557\n",
      "     12       \u001b[36m30.6270\u001b[0m       40.0641  0.0005  13.6387\n",
      "     12       \u001b[36m24.1120\u001b[0m       44.6312  0.0005  13.9146\n",
      "     13       \u001b[36m26.2338\u001b[0m       \u001b[32m40.6392\u001b[0m  0.0010  13.8663\n",
      "     13       \u001b[36m16.5766\u001b[0m       \u001b[32m36.9972\u001b[0m  0.0005  13.9946\n",
      "     13       \u001b[36m24.2058\u001b[0m       \u001b[32m32.3605\u001b[0m  0.0010  13.9804\n",
      "     13       \u001b[36m24.8536\u001b[0m       39.8022  0.0005  13.9516\n",
      "     13       \u001b[36m20.9014\u001b[0m       44.9434  0.0005  14.1367\n",
      "     14       \u001b[36m20.1769\u001b[0m       \u001b[32m25.0228\u001b[0m  0.0010  13.3224\n",
      "     14       \u001b[36m14.1652\u001b[0m       37.6821  0.0005  13.6062\n",
      "     14       \u001b[36m17.4498\u001b[0m       43.8519  0.0010  13.6351\n",
      "     14       \u001b[36m19.4221\u001b[0m       \u001b[32m36.7467\u001b[0m  0.0005  13.4782\n",
      "     14       \u001b[36m17.6211\u001b[0m       52.6028  0.0005  13.5590\n",
      "     15       \u001b[36m16.6885\u001b[0m       \u001b[32m23.8066\u001b[0m  0.0010  13.1159\n",
      "     15       \u001b[36m12.6935\u001b[0m       47.1140  0.0005  13.1086\n",
      "     15       \u001b[36m15.0600\u001b[0m       35.5611  0.0010  13.3225\n",
      "     15       \u001b[36m16.4899\u001b[0m       37.2472  0.0005  13.3176\n",
      "     15       \u001b[36m14.8411\u001b[0m       59.1180  0.0005  13.4348\n",
      "     16       \u001b[36m13.8598\u001b[0m       28.5283  0.0010  13.9074\n",
      "     16       \u001b[36m11.6347\u001b[0m       52.8839  0.0005  13.9250\n",
      "     16       \u001b[36m14.4619\u001b[0m       38.3210  0.0010  13.8928\n",
      "     16       \u001b[36m14.4955\u001b[0m       39.6155  0.0005  13.9985\n",
      "     17       \u001b[36m13.2252\u001b[0m       39.6159  0.0010  13.1168\n",
      "     17       \u001b[36m10.8643\u001b[0m       42.9518  0.0005  12.9297\n",
      "     17       \u001b[36m13.6574\u001b[0m       \u001b[32m29.1193\u001b[0m  0.0010  12.9114\n",
      "     17       \u001b[36m12.8207\u001b[0m       39.0145  0.0005  12.8980\n",
      "     18       \u001b[36m11.9992\u001b[0m       37.6731  0.0010  12.7223\n",
      "     18       \u001b[36m10.8054\u001b[0m       \u001b[32m36.1227\u001b[0m  0.0003  12.5759\n",
      "     18       \u001b[36m12.9245\u001b[0m       \u001b[32m28.4932\u001b[0m  0.0010  12.9410\n",
      "     18       \u001b[36m11.4867\u001b[0m       36.8714  0.0005  13.0922\n",
      "     19       \u001b[36m11.5530\u001b[0m       44.9788  0.0010  12.4310\n",
      "     19       11.3007       \u001b[32m32.9843\u001b[0m  0.0003  12.0366\n",
      "     19       \u001b[36m11.9336\u001b[0m       37.1690  0.0010  12.5240\n",
      "     19       \u001b[36m10.7264\u001b[0m       \u001b[32m31.2644\u001b[0m  0.0003  12.5353\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "     20       \u001b[36m10.3820\u001b[0m       \u001b[32m31.0674\u001b[0m  0.0003  12.3161\n",
      "     20       12.2287       37.6390  0.0010  12.2106\n",
      "     20       \u001b[36m10.1093\u001b[0m       34.2410  0.0003  12.1790\n",
      "     21        \u001b[36m9.9796\u001b[0m       31.3662  0.0003  10.6299\n",
      "     21       12.9796       33.3033  0.0010  10.7855\n",
      "     21        \u001b[36m9.6672\u001b[0m       35.6835  0.0003  10.7616\n",
      "     22        \u001b[36m9.7603\u001b[0m       32.2115  0.0003  10.2494\n",
      "     22       13.9433       32.6120  0.0010  10.4159\n",
      "     22        \u001b[36m9.3432\u001b[0m       35.6256  0.0003  10.3611\n",
      "     23        \u001b[36m9.5862\u001b[0m       33.0572  0.0003  9.8474\n",
      "     23       12.5086       \u001b[32m24.7448\u001b[0m  0.0005  10.1169\n",
      "     23        \u001b[36m9.0723\u001b[0m       35.6827  0.0003  10.1992\n",
      "     24        \u001b[36m9.4388\u001b[0m       34.3565  0.0003  9.9110\n",
      "     24       \u001b[36m10.3414\u001b[0m       \u001b[32m22.9826\u001b[0m  0.0005  10.1257\n",
      "     24        \u001b[36m8.9997\u001b[0m       \u001b[32m31.0200\u001b[0m  0.0001  10.1215\n",
      "     25        \u001b[36m9.2119\u001b[0m       \u001b[32m21.8788\u001b[0m  0.0005  10.0271\n",
      "     25        \u001b[36m8.3981\u001b[0m       31.7060  0.0001  9.9859\n",
      "     26        \u001b[36m8.2205\u001b[0m       \u001b[32m21.3119\u001b[0m  0.0005  8.9958\n",
      "     26        \u001b[36m8.1466\u001b[0m       31.5788  0.0001  8.9745\n",
      "     27        \u001b[36m7.5215\u001b[0m       \u001b[32m21.0338\u001b[0m  0.0005  8.6119\n",
      "     27        \u001b[36m7.9631\u001b[0m       31.5804  0.0001  8.6733\n",
      "     28        \u001b[36m6.9912\u001b[0m       \u001b[32m20.8015\u001b[0m  0.0005  8.9223\n",
      "     28        \u001b[36m7.8052\u001b[0m       31.7230  0.0001  8.8654\n",
      "     29        \u001b[36m6.6487\u001b[0m       \u001b[32m20.7791\u001b[0m  0.0005  8.6080\n",
      "     29        \u001b[36m7.4992\u001b[0m       \u001b[32m28.9462\u001b[0m  0.0001  8.7616\n",
      "     30        \u001b[36m6.4234\u001b[0m       \u001b[32m20.7244\u001b[0m  0.0005  8.5641\n",
      "     30        \u001b[36m7.4282\u001b[0m       29.0454  0.0001  8.6019\n",
      "     31        \u001b[36m6.2763\u001b[0m       20.7994  0.0005  8.6467\n",
      "     31        \u001b[36m7.3371\u001b[0m       29.0228  0.0001  8.6738\n",
      "     32        \u001b[36m6.1634\u001b[0m       \u001b[32m20.7161\u001b[0m  0.0005  8.5889\n",
      "     32        \u001b[36m7.2619\u001b[0m       28.9740  0.0001  8.5771\n",
      "     33        \u001b[36m6.0721\u001b[0m       20.7357  0.0005  8.7658\n",
      "     33        \u001b[36m7.1938\u001b[0m       28.9635  0.0001  8.7149\n",
      "     34        \u001b[36m5.9935\u001b[0m       \u001b[32m20.7056\u001b[0m  0.0005  8.7892\n",
      "     35        \u001b[36m5.9275\u001b[0m       20.7544  0.0005  7.8970\n",
      "     36        \u001b[36m5.8674\u001b[0m       20.8279  0.0005  7.3333\n",
      "     37        \u001b[36m5.8151\u001b[0m       20.9192  0.0005  7.2577\n",
      "     38        \u001b[36m5.7693\u001b[0m       21.0172  0.0005  7.2719\n",
      "RMSE for each folder: [5.78761098 5.06845985 5.203787   4.4228672  3.89606056]\n",
      "RMSE mean: 4.875757118104529\n"
     ]
    }
   ],
   "source": [
    "## NN method\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Unflatten(1, (8,500)), #unflatten data for  convolution (64 (batch_size), 8,500)\n",
    "\n",
    "            nn.Conv1d(8, 32, kernel_size=11, padding=5), # 8 input channels (electrodes) and 32 is the output, the number of feature he learn.\n",
    "            # Thanks to padding, the output length remains 500 (64,32,500) \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),  # Halve the temporal dimension  (64,32,250)          \n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=9, padding=4), #(64,64,250)\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),  #(64,64,125)      \n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3), # (64,128,125)\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),  # (64,128,62)    \n",
    "            \n",
    "            nn.Flatten(), # Reflatten our data for the next part (64,128*62)\n",
    "        )\n",
    "        self.r = nn.Sequential(\n",
    "            nn.Linear(7936, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 51),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(x)\n",
    "        return self.r(x)\n",
    "\n",
    "      \n",
    "# Convert dataset from float64 to float32 because PyTorch layers expect float32\n",
    "# 32-bit precision is sufficient for our signals and speeds up training\n",
    "print(X_g_train_wdw_flat.dtype)   \n",
    "print(y_g_train_wdw_flat.dtype)   \n",
    "\n",
    "x = X_g_train_wdw_flat.astype('float32')\n",
    "y = y_g_train_wdw_flat.astype('float32')\n",
    "\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    module=NeuralNetwork,                 # PyTorch model \n",
    "    max_epochs=100,                 \n",
    "    lr=1e-3,                       \n",
    "    batch_size=64,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[('earlystop', EarlyStopping('valid_loss', patience=5)), # Stop if validation loss doesn't improve for 5 epochs \n",
    "                    ('lr_sched', LRScheduler(\n",
    "           policy=torch.optim.lr_scheduler.ReduceLROnPlateau, # Halve LR if validation loss stalls for 3 epochs\n",
    "           monitor='valid_loss',\n",
    "           patience=3, factor=0.5))]\n",
    ")\n",
    "\n",
    "\n",
    "pipe_nn = Pipeline([\n",
    "    ('scale', StandardScaler()),  # Standardize inputs for a quick start, after the cnn will then normalize its data at each step\n",
    "    ('net',   net)                \n",
    "])\n",
    "\n",
    "\n",
    "cross_validation_with_scores(x,y,groups,pipe_nn,logo,rmse_scorer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdb180-6ce2-42f5-8745-04c47650ba73",
   "metadata": {},
   "source": [
    "The mean rmse for this cnn was better than that of the covariance pipeline, but it takes a really long time to execute compared to that method. If only I could have the benefits of both approachesâ€¦\n",
    "\n",
    "It was with this train of thought that I created a hybrid between the cnn and the covariance matrice method. For this hybrid, I didnâ€™t need a CNN because the data after the covariance matrice step was  small, so I just built a two-layer nn and the results are very close to the cnn but it runs much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127f6c1-c9b2-47df-878b-aa7e2cfa63d6",
   "metadata": {},
   "source": [
    "![](./images/5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e5ee8f6-481f-4723-bd8c-96a023576f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/home/khalil/ls/envs/sfml/lib/python3.12/site-packages/skorch/net.py:2261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001b[36m470.8343\u001b[0m      \u001b[32m414.6853\u001b[0m  0.0010  0.1712\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001b[36m463.6166\u001b[0m      \u001b[32m378.4322\u001b[0m  0.0010  0.1656\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001b[36m467.2118\u001b[0m      \u001b[32m401.8539\u001b[0m  0.0010  0.1606\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001b[36m464.6680\u001b[0m      \u001b[32m383.2886\u001b[0m  0.0010  0.1629\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001b[36m468.2206\u001b[0m      \u001b[32m396.6849\u001b[0m  0.0010  0.1362\n",
      "      2      \u001b[36m292.4210\u001b[0m      \u001b[32m191.6098\u001b[0m  0.0010  0.1378\n",
      "      2      \u001b[36m270.0458\u001b[0m      \u001b[32m177.9767\u001b[0m  0.0010  0.1408\n",
      "      2      \u001b[36m294.1228\u001b[0m      \u001b[32m185.2847\u001b[0m  0.0010  0.1309\n",
      "      2      \u001b[36m278.3946\u001b[0m      \u001b[32m178.0234\u001b[0m  0.0010  0.1322\n",
      "      2      \u001b[36m286.0455\u001b[0m      \u001b[32m179.3958\u001b[0m  0.0010  0.1533\n",
      "      3      \u001b[36m169.3120\u001b[0m      \u001b[32m142.6608\u001b[0m  0.0010  0.1482\n",
      "      3      \u001b[36m169.6744\u001b[0m      \u001b[32m130.8277\u001b[0m  0.0010  0.1405\n",
      "      3      \u001b[36m170.2517\u001b[0m      \u001b[32m144.0836\u001b[0m  0.0010  0.1457\n",
      "      3      \u001b[36m169.2939\u001b[0m      \u001b[32m134.8716\u001b[0m  0.0010  0.1475\n",
      "      3      \u001b[36m164.7098\u001b[0m      \u001b[32m133.9635\u001b[0m  0.0010  0.1451\n",
      "      4      \u001b[36m150.0924\u001b[0m      \u001b[32m134.6463\u001b[0m  0.0010  0.1179\n",
      "      4      \u001b[36m139.0527\u001b[0m      \u001b[32m124.8156\u001b[0m  0.0010  0.1404\n",
      "      4      \u001b[36m138.5201\u001b[0m      \u001b[32m111.8254\u001b[0m  0.0010  0.1393\n",
      "      4      \u001b[36m142.4911\u001b[0m      \u001b[32m120.9991\u001b[0m  0.0010  0.1393\n",
      "      4      \u001b[36m137.1338\u001b[0m      \u001b[32m118.4867\u001b[0m  0.0010  0.1578\n",
      "      5      \u001b[36m136.3324\u001b[0m      \u001b[32m128.9582\u001b[0m  0.0010  0.1586\n",
      "      5      \u001b[36m123.2785\u001b[0m      \u001b[32m113.2610\u001b[0m  0.0010  0.1655\n",
      "      5      \u001b[36m119.1474\u001b[0m       \u001b[32m98.3868\u001b[0m  0.0010  0.1578\n",
      "      5      \u001b[36m123.8227\u001b[0m      \u001b[32m109.3364\u001b[0m  0.0010  0.1779\n",
      "      5      \u001b[36m119.7081\u001b[0m      \u001b[32m104.1072\u001b[0m  0.0010  0.1566\n",
      "      6      \u001b[36m103.1638\u001b[0m       \u001b[32m89.1552\u001b[0m  0.0010  0.1185\n",
      "      6      \u001b[36m124.6429\u001b[0m      \u001b[32m115.3955\u001b[0m  0.0010  0.1440\n",
      "      6      \u001b[36m110.2072\u001b[0m      \u001b[32m104.4360\u001b[0m  0.0010  0.1369\n",
      "      6      \u001b[36m109.7642\u001b[0m      \u001b[32m102.4752\u001b[0m  0.0010  0.1493\n",
      "      7      \u001b[36m114.7682\u001b[0m      \u001b[32m107.0560\u001b[0m  0.0010  0.1287\n",
      "      7       \u001b[36m97.0113\u001b[0m       \u001b[32m82.0843\u001b[0m  0.0010  0.1472\n",
      "      6      \u001b[36m104.9700\u001b[0m       \u001b[32m90.5853\u001b[0m  0.0010  0.1513\n",
      "      7      \u001b[36m101.2699\u001b[0m       \u001b[32m97.1926\u001b[0m  0.0010  0.1382\n",
      "      7      \u001b[36m100.9849\u001b[0m       \u001b[32m96.6630\u001b[0m  0.0010  0.1266\n",
      "      8      \u001b[36m102.8742\u001b[0m       \u001b[32m99.6199\u001b[0m  0.0010  0.1174\n",
      "      8       \u001b[36m92.5464\u001b[0m       \u001b[32m76.9047\u001b[0m  0.0010  0.1312\n",
      "      8       \u001b[36m92.9132\u001b[0m       \u001b[32m92.4244\u001b[0m  0.0010  0.1270\n",
      "      7       \u001b[36m94.4908\u001b[0m       \u001b[32m81.1219\u001b[0m  0.0010  0.1368\n",
      "      8       \u001b[36m95.5697\u001b[0m       \u001b[32m90.0735\u001b[0m  0.0010  0.1367\n",
      "      9       \u001b[36m94.5252\u001b[0m       \u001b[32m90.2367\u001b[0m  0.0010  0.1418\n",
      "      9       \u001b[36m88.5717\u001b[0m       \u001b[32m73.2499\u001b[0m  0.0010  0.1432\n",
      "      9       \u001b[36m88.2698\u001b[0m       \u001b[32m86.4924\u001b[0m  0.0010  0.1636\n",
      "      8       \u001b[36m87.0875\u001b[0m       \u001b[32m74.4957\u001b[0m  0.0010  0.1689\n",
      "      9       \u001b[36m91.3277\u001b[0m       \u001b[32m84.4971\u001b[0m  0.0010  0.1584\n",
      "     10       \u001b[36m88.9272\u001b[0m       \u001b[32m82.9708\u001b[0m  0.0010  0.1711\n",
      "     10       \u001b[36m84.3198\u001b[0m       \u001b[32m70.4643\u001b[0m  0.0010  0.1502\n",
      "     10       \u001b[36m84.6446\u001b[0m       \u001b[32m82.2150\u001b[0m  0.0010  0.1496\n",
      "      9       \u001b[36m81.3593\u001b[0m       \u001b[32m69.3028\u001b[0m  0.0010  0.1489\n",
      "     10       \u001b[36m85.9294\u001b[0m       \u001b[32m79.7707\u001b[0m  0.0010  0.1563\n",
      "     11       \u001b[36m85.5812\u001b[0m       \u001b[32m79.4515\u001b[0m  0.0010  0.1233\n",
      "     11       \u001b[36m82.4376\u001b[0m       \u001b[32m66.7117\u001b[0m  0.0010  0.1425\n",
      "     11       \u001b[36m82.2634\u001b[0m       \u001b[32m78.3662\u001b[0m  0.0010  0.1499\n",
      "     10       \u001b[36m74.9969\u001b[0m       \u001b[32m65.4609\u001b[0m  0.0010  0.1554\n",
      "     12       \u001b[36m81.6722\u001b[0m       \u001b[32m76.0789\u001b[0m  0.0010  0.1518\n",
      "     11       \u001b[36m81.4118\u001b[0m       \u001b[32m77.0025\u001b[0m  0.0010  0.1604\n",
      "     12       \u001b[36m79.7780\u001b[0m       \u001b[32m64.6904\u001b[0m  0.0010  0.1368\n",
      "     12       \u001b[36m78.3760\u001b[0m       \u001b[32m74.7948\u001b[0m  0.0010  0.1369\n",
      "     11       \u001b[36m71.7416\u001b[0m       \u001b[32m62.4418\u001b[0m  0.0010  0.1425\n",
      "     12       \u001b[36m78.9688\u001b[0m       \u001b[32m72.1015\u001b[0m  0.0010  0.1387\n",
      "     13       \u001b[36m78.4508\u001b[0m       \u001b[32m71.9932\u001b[0m  0.0010  0.1434\n",
      "     13       \u001b[36m75.5186\u001b[0m       \u001b[32m62.3209\u001b[0m  0.0010  0.1368\n",
      "     13       \u001b[36m74.9912\u001b[0m       \u001b[32m71.5764\u001b[0m  0.0010  0.1392\n",
      "     12       \u001b[36m66.9707\u001b[0m       \u001b[32m58.4378\u001b[0m  0.0010  0.1313\n",
      "     14       \u001b[36m74.2938\u001b[0m       \u001b[32m69.9607\u001b[0m  0.0010  0.1342\n",
      "     13       \u001b[36m75.4621\u001b[0m       \u001b[32m69.5805\u001b[0m  0.0010  0.1424\n",
      "     14       \u001b[36m74.4946\u001b[0m       \u001b[32m59.7921\u001b[0m  0.0010  0.1468\n",
      "     13       \u001b[36m65.8100\u001b[0m       \u001b[32m55.3466\u001b[0m  0.0010  0.1286\n",
      "     14       \u001b[36m71.3900\u001b[0m       \u001b[32m68.4857\u001b[0m  0.0010  0.1422\n",
      "     15       \u001b[36m71.6792\u001b[0m       \u001b[32m63.8451\u001b[0m  0.0010  0.1128\n",
      "     14       \u001b[36m73.4762\u001b[0m       \u001b[32m66.7747\u001b[0m  0.0010  0.1126\n",
      "     15       \u001b[36m70.0578\u001b[0m       \u001b[32m56.9536\u001b[0m  0.0010  0.1183\n",
      "     14       \u001b[36m63.1588\u001b[0m       55.6605  0.0010  0.1148\n",
      "     15       \u001b[36m69.4448\u001b[0m       \u001b[32m67.1844\u001b[0m  0.0010  0.1333\n",
      "     15       \u001b[36m68.7931\u001b[0m       \u001b[32m63.8433\u001b[0m  0.0010  0.1252\n",
      "     16       \u001b[36m68.7687\u001b[0m       \u001b[32m60.7431\u001b[0m  0.0010  0.1380\n",
      "     16       \u001b[36m67.5813\u001b[0m       \u001b[32m55.9848\u001b[0m  0.0010  0.1200\n",
      "     15       \u001b[36m61.0704\u001b[0m       \u001b[32m52.9673\u001b[0m  0.0010  0.1559\n",
      "     16       \u001b[36m67.1309\u001b[0m       \u001b[32m63.5517\u001b[0m  0.0010  0.1529\n",
      "     17       \u001b[36m66.6282\u001b[0m       \u001b[32m59.7506\u001b[0m  0.0010  0.1339\n",
      "     17       \u001b[36m65.6946\u001b[0m       \u001b[32m53.2988\u001b[0m  0.0010  0.1297\n",
      "     16       \u001b[36m67.9596\u001b[0m       \u001b[32m60.4048\u001b[0m  0.0010  0.1446\n",
      "     16       \u001b[36m58.1278\u001b[0m       \u001b[32m51.2670\u001b[0m  0.0010  0.1275\n",
      "     17       \u001b[36m64.7710\u001b[0m       \u001b[32m60.7775\u001b[0m  0.0010  0.1370\n",
      "     18       \u001b[36m64.1857\u001b[0m       \u001b[32m51.0931\u001b[0m  0.0010  0.1301\n",
      "     18       \u001b[36m63.0448\u001b[0m       \u001b[32m57.0963\u001b[0m  0.0010  0.1327\n",
      "     17       \u001b[36m63.8964\u001b[0m       \u001b[32m58.6361\u001b[0m  0.0010  0.1317\n",
      "     17       \u001b[36m58.0420\u001b[0m       \u001b[32m50.9205\u001b[0m  0.0010  0.1319\n",
      "     18       \u001b[36m64.1271\u001b[0m       \u001b[32m58.9939\u001b[0m  0.0010  0.1495\n",
      "     19       \u001b[36m63.0897\u001b[0m       \u001b[32m50.2215\u001b[0m  0.0010  0.1258\n",
      "     19       \u001b[36m60.8399\u001b[0m       57.5792  0.0010  0.1331\n",
      "     18       \u001b[36m61.2088\u001b[0m       \u001b[32m55.7935\u001b[0m  0.0010  0.1343\n",
      "     18       \u001b[36m56.7549\u001b[0m       \u001b[32m48.7972\u001b[0m  0.0010  0.1473\n",
      "     19       \u001b[36m61.4262\u001b[0m       \u001b[32m57.7818\u001b[0m  0.0010  0.1258\n",
      "     20       \u001b[36m60.7226\u001b[0m       \u001b[32m49.5679\u001b[0m  0.0010  0.1276\n",
      "     20       \u001b[36m60.5848\u001b[0m       \u001b[32m53.4937\u001b[0m  0.0010  0.1258\n",
      "     19       \u001b[36m59.4446\u001b[0m       \u001b[32m52.9634\u001b[0m  0.0010  0.1372\n",
      "     19       \u001b[36m53.2064\u001b[0m       \u001b[32m46.9963\u001b[0m  0.0010  0.1321\n",
      "     20       \u001b[36m59.7798\u001b[0m       \u001b[32m56.1719\u001b[0m  0.0010  0.1330\n",
      "     21       \u001b[36m58.7945\u001b[0m       \u001b[32m47.6685\u001b[0m  0.0010  0.1287\n",
      "     21       \u001b[36m59.2749\u001b[0m       \u001b[32m52.2821\u001b[0m  0.0010  0.1218\n",
      "     20       \u001b[36m57.6353\u001b[0m       \u001b[32m51.2050\u001b[0m  0.0010  0.1180\n",
      "     20       \u001b[36m52.7652\u001b[0m       \u001b[32m45.6495\u001b[0m  0.0010  0.1505\n",
      "     21       \u001b[36m57.2797\u001b[0m       \u001b[32m54.4713\u001b[0m  0.0010  0.1475\n",
      "     22       \u001b[36m57.1396\u001b[0m       \u001b[32m46.9060\u001b[0m  0.0010  0.1420\n",
      "     22       \u001b[36m56.0850\u001b[0m       \u001b[32m49.7561\u001b[0m  0.0010  0.1497\n",
      "     21       \u001b[36m56.0397\u001b[0m       \u001b[32m49.7489\u001b[0m  0.0010  0.1516\n",
      "     21       \u001b[36m52.2870\u001b[0m       \u001b[32m44.1432\u001b[0m  0.0010  0.1355\n",
      "     22       \u001b[36m56.5964\u001b[0m       \u001b[32m54.1741\u001b[0m  0.0010  0.1149\n",
      "     23       \u001b[36m56.8734\u001b[0m       \u001b[32m44.9212\u001b[0m  0.0010  0.1207\n",
      "     23       \u001b[36m55.4393\u001b[0m       \u001b[32m47.8678\u001b[0m  0.0010  0.1185\n",
      "     22       \u001b[36m53.3098\u001b[0m       \u001b[32m48.3036\u001b[0m  0.0010  0.1076\n",
      "     23       \u001b[36m55.8944\u001b[0m       \u001b[32m53.0768\u001b[0m  0.0010  0.1206\n",
      "     22       \u001b[36m51.4725\u001b[0m       44.1736  0.0010  0.1257\n",
      "     24       \u001b[36m55.3736\u001b[0m       \u001b[32m44.0799\u001b[0m  0.0010  0.1219\n",
      "     23       \u001b[36m52.1946\u001b[0m       \u001b[32m46.3541\u001b[0m  0.0010  0.1216\n",
      "     24       \u001b[36m53.7999\u001b[0m       \u001b[32m47.6220\u001b[0m  0.0010  0.1282\n",
      "     23       \u001b[36m50.8301\u001b[0m       \u001b[32m42.1490\u001b[0m  0.0010  0.1148\n",
      "     24       \u001b[36m54.5153\u001b[0m       \u001b[32m51.0553\u001b[0m  0.0010  0.1205\n",
      "     25       \u001b[36m55.1471\u001b[0m       \u001b[32m42.5680\u001b[0m  0.0010  0.1309\n",
      "     24       \u001b[36m51.3345\u001b[0m       \u001b[32m44.5782\u001b[0m  0.0010  0.1316\n",
      "     25       \u001b[36m52.8346\u001b[0m       \u001b[32m46.8922\u001b[0m  0.0010  0.1290\n",
      "     24       \u001b[36m49.3214\u001b[0m       \u001b[32m39.1046\u001b[0m  0.0010  0.1290\n",
      "     25       \u001b[36m53.0368\u001b[0m       \u001b[32m50.7498\u001b[0m  0.0010  0.1276\n",
      "     26       \u001b[36m52.3856\u001b[0m       \u001b[32m42.2434\u001b[0m  0.0010  0.1098\n",
      "     25       \u001b[36m49.7968\u001b[0m       \u001b[32m42.6286\u001b[0m  0.0010  0.1167\n",
      "     26       \u001b[36m51.4202\u001b[0m       \u001b[32m44.2756\u001b[0m  0.0010  0.1231\n",
      "     27       52.6468       \u001b[32m40.8763\u001b[0m  0.0010  0.1159\n",
      "     25       \u001b[36m47.4629\u001b[0m       \u001b[32m38.5874\u001b[0m  0.0010  0.1298\n",
      "     26       \u001b[36m52.0126\u001b[0m       \u001b[32m49.9346\u001b[0m  0.0010  0.1401\n",
      "     27       \u001b[36m49.7449\u001b[0m       \u001b[32m42.8801\u001b[0m  0.0010  0.1151\n",
      "     26       \u001b[36m48.9519\u001b[0m       \u001b[32m41.8962\u001b[0m  0.0010  0.1375\n",
      "     28       \u001b[36m50.9069\u001b[0m       \u001b[32m40.2978\u001b[0m  0.0010  0.1288\n",
      "     26       \u001b[36m44.2894\u001b[0m       39.0352  0.0010  0.1342\n",
      "     27       \u001b[36m50.7991\u001b[0m       \u001b[32m49.4285\u001b[0m  0.0010  0.1361\n",
      "     28       \u001b[36m49.3022\u001b[0m       43.7278  0.0010  0.1363\n",
      "     27       49.1219       \u001b[32m40.3085\u001b[0m  0.0010  0.1361\n",
      "     29       \u001b[36m49.8265\u001b[0m       \u001b[32m38.0846\u001b[0m  0.0010  0.1128\n",
      "     28       \u001b[36m50.6185\u001b[0m       \u001b[32m47.2053\u001b[0m  0.0010  0.1166\n",
      "     29       \u001b[36m48.3425\u001b[0m       \u001b[32m41.4175\u001b[0m  0.0010  0.1070\n",
      "     27       45.0696       \u001b[32m37.8398\u001b[0m  0.0010  0.1365\n",
      "     28       \u001b[36m47.7654\u001b[0m       \u001b[32m38.5049\u001b[0m  0.0010  0.1181\n",
      "     30       \u001b[36m48.8802\u001b[0m       \u001b[32m36.7056\u001b[0m  0.0010  0.1210\n",
      "     30       \u001b[36m47.3988\u001b[0m       \u001b[32m38.6161\u001b[0m  0.0010  0.1044\n",
      "     28       44.6920       \u001b[32m36.0802\u001b[0m  0.0010  0.1157\n",
      "     29       \u001b[36m47.9698\u001b[0m       \u001b[32m45.5405\u001b[0m  0.0010  0.1250\n",
      "     29       \u001b[36m46.4076\u001b[0m       \u001b[32m38.1878\u001b[0m  0.0010  0.1369\n",
      "     31       \u001b[36m48.0503\u001b[0m       \u001b[32m36.1182\u001b[0m  0.0010  0.1113\n",
      "     31       \u001b[36m46.2074\u001b[0m       \u001b[32m37.3275\u001b[0m  0.0010  0.1148\n",
      "     29       \u001b[36m43.4478\u001b[0m       \u001b[32m34.6977\u001b[0m  0.0010  0.1265\n",
      "     30       48.3807       45.7700  0.0010  0.1366\n",
      "     30       \u001b[36m45.9212\u001b[0m       \u001b[32m36.3060\u001b[0m  0.0010  0.1351\n",
      "     32       48.2002       \u001b[32m35.8410\u001b[0m  0.0010  0.1230\n",
      "     32       \u001b[36m44.9503\u001b[0m       \u001b[32m36.7964\u001b[0m  0.0010  0.1250\n",
      "     30       \u001b[36m42.3288\u001b[0m       \u001b[32m33.2516\u001b[0m  0.0010  0.1318\n",
      "     31       \u001b[36m46.1708\u001b[0m       \u001b[32m45.4042\u001b[0m  0.0010  0.1434\n",
      "     31       \u001b[36m45.2705\u001b[0m       \u001b[32m35.8095\u001b[0m  0.0010  0.1359\n",
      "     33       \u001b[36m47.3691\u001b[0m       \u001b[32m35.4133\u001b[0m  0.0010  0.1182\n",
      "     33       \u001b[36m44.5083\u001b[0m       \u001b[32m35.5066\u001b[0m  0.0010  0.1229\n",
      "     31       \u001b[36m41.8201\u001b[0m       33.5579  0.0010  0.1327\n",
      "     32       \u001b[36m45.0762\u001b[0m       \u001b[32m43.7094\u001b[0m  0.0010  0.1322\n",
      "     32       \u001b[36m44.8855\u001b[0m       \u001b[32m35.7989\u001b[0m  0.0010  0.1174\n",
      "     34       \u001b[36m45.5393\u001b[0m       \u001b[32m35.3002\u001b[0m  0.0010  0.1271\n",
      "     34       \u001b[36m43.1079\u001b[0m       35.8146  0.0010  0.1280\n",
      "     32       41.9485       33.3108  0.0010  0.1046\n",
      "     33       \u001b[36m43.9300\u001b[0m       \u001b[32m35.3111\u001b[0m  0.0010  0.1119\n",
      "     33       46.5366       43.9292  0.0010  0.1257\n",
      "     35       \u001b[36m44.6683\u001b[0m       \u001b[32m33.2586\u001b[0m  0.0010  0.1316\n",
      "     35       \u001b[36m41.8308\u001b[0m       \u001b[32m33.3933\u001b[0m  0.0010  0.1212\n",
      "     33       \u001b[36m40.4113\u001b[0m       34.0193  0.0010  0.1346\n",
      "     34       \u001b[36m42.3210\u001b[0m       \u001b[32m34.1190\u001b[0m  0.0010  0.1369\n",
      "     34       \u001b[36m44.2332\u001b[0m       \u001b[32m43.1010\u001b[0m  0.0010  0.1352\n",
      "     36       42.4729       \u001b[32m32.0905\u001b[0m  0.0010  0.1414\n",
      "     36       \u001b[36m43.9769\u001b[0m       \u001b[32m32.5693\u001b[0m  0.0010  0.1540\n",
      "     34       40.7879       \u001b[32m31.6167\u001b[0m  0.0010  0.1506\n",
      "     35       \u001b[36m42.8971\u001b[0m       \u001b[32m41.3855\u001b[0m  0.0010  0.1443\n",
      "     35       \u001b[36m41.5576\u001b[0m       \u001b[32m32.9247\u001b[0m  0.0010  0.1485\n",
      "     37       \u001b[36m41.5739\u001b[0m       34.8214  0.0010  0.1393\n",
      "     37       44.8172       \u001b[32m31.1719\u001b[0m  0.0010  0.1422\n",
      "     35       40.7737       \u001b[32m31.5045\u001b[0m  0.0010  0.1567\n",
      "     36       42.9945       \u001b[32m41.1366\u001b[0m  0.0010  0.1303\n",
      "     36       42.6232       \u001b[32m31.9819\u001b[0m  0.0010  0.1354\n",
      "     38       \u001b[36m40.3852\u001b[0m       32.5607  0.0010  0.1342\n",
      "     38       \u001b[36m42.2367\u001b[0m       31.2637  0.0010  0.1296\n",
      "     36       \u001b[36m38.4978\u001b[0m       \u001b[32m29.8053\u001b[0m  0.0010  0.1474\n",
      "     37       43.1250       \u001b[32m40.3482\u001b[0m  0.0010  0.1330\n",
      "     37       \u001b[36m40.9039\u001b[0m       \u001b[32m31.8154\u001b[0m  0.0010  0.1494\n",
      "     39       40.3955       \u001b[32m31.6289\u001b[0m  0.0010  0.1158\n",
      "     39       42.2679       31.7094  0.0010  0.1344\n",
      "     38       \u001b[36m41.6744\u001b[0m       41.4710  0.0010  0.1321\n",
      "     38       \u001b[36m39.9424\u001b[0m       \u001b[32m31.2777\u001b[0m  0.0010  0.1164\n",
      "     37       \u001b[36m38.0612\u001b[0m       30.1141  0.0010  0.1424\n",
      "     40       \u001b[36m39.7438\u001b[0m       \u001b[32m31.3231\u001b[0m  0.0010  0.1084\n",
      "     40       \u001b[36m41.7180\u001b[0m       \u001b[32m29.9843\u001b[0m  0.0010  0.1360\n",
      "     39       \u001b[36m40.7481\u001b[0m       \u001b[32m38.4533\u001b[0m  0.0010  0.1237\n",
      "     39       40.0644       \u001b[32m30.5360\u001b[0m  0.0010  0.1164\n",
      "     38       38.0798       30.4726  0.0010  0.1189\n",
      "     41       \u001b[36m38.5173\u001b[0m       \u001b[32m30.0122\u001b[0m  0.0010  0.1151\n",
      "     41       \u001b[36m40.2480\u001b[0m       \u001b[32m29.8273\u001b[0m  0.0010  0.1170\n",
      "     40       \u001b[36m38.5943\u001b[0m       \u001b[32m29.3203\u001b[0m  0.0010  0.1101\n",
      "     40       \u001b[36m40.0594\u001b[0m       39.0159  0.0010  0.1160\n",
      "     42       39.3442       \u001b[32m29.8317\u001b[0m  0.0010  0.1177\n",
      "     39       \u001b[36m36.5984\u001b[0m       30.1142  0.0010  0.1220\n",
      "     42       41.9263       \u001b[32m29.1716\u001b[0m  0.0010  0.1222\n",
      "     41       40.7789       \u001b[32m38.3068\u001b[0m  0.0010  0.1216\n",
      "     41       38.6570       29.6715  0.0010  0.1251\n",
      "     43       39.7067       \u001b[32m27.9305\u001b[0m  0.0010  0.1162\n",
      "     40       36.8855       \u001b[32m29.2346\u001b[0m  0.0010  0.1333\n",
      "     43       42.0166       29.3652  0.0010  0.1040\n",
      "     44       \u001b[36m38.1948\u001b[0m       \u001b[32m27.8016\u001b[0m  0.0010  0.1108\n",
      "     42       \u001b[36m37.5869\u001b[0m       29.9092  0.0010  0.1180\n",
      "     42       \u001b[36m37.7310\u001b[0m       38.3842  0.0010  0.1360\n",
      "     41       \u001b[36m36.4072\u001b[0m       \u001b[32m27.5321\u001b[0m  0.0010  0.1209\n",
      "     44       \u001b[36m39.7404\u001b[0m       \u001b[32m28.6547\u001b[0m  0.0010  0.1276\n",
      "     45       38.3843       \u001b[32m27.7136\u001b[0m  0.0010  0.1080\n",
      "     43       39.1394       \u001b[32m29.0461\u001b[0m  0.0010  0.1174\n",
      "     42       37.5022       28.5204  0.0010  0.1169\n",
      "     43       39.9031       \u001b[32m37.0685\u001b[0m  0.0010  0.1304\n",
      "     45       \u001b[36m39.2621\u001b[0m       \u001b[32m28.0385\u001b[0m  0.0010  0.1146\n",
      "     44       38.6551       \u001b[32m28.4415\u001b[0m  0.0010  0.0983\n",
      "     46       \u001b[36m37.7183\u001b[0m       28.0135  0.0010  0.1341\n",
      "     44       37.8259       37.4105  0.0010  0.1105\n",
      "     43       \u001b[36m35.6912\u001b[0m       28.3516  0.0010  0.1319\n",
      "     46       40.7691       28.4838  0.0010  0.1064\n",
      "     45       \u001b[36m36.8888\u001b[0m       \u001b[32m28.3115\u001b[0m  0.0010  0.1313\n",
      "     45       38.8297       37.1027  0.0010  0.1099\n",
      "     47       \u001b[36m36.7200\u001b[0m       \u001b[32m27.3709\u001b[0m  0.0010  0.1350\n",
      "     44       36.0571       \u001b[32m27.4763\u001b[0m  0.0010  0.1075\n",
      "     47       39.8061       \u001b[32m27.6642\u001b[0m  0.0010  0.1056\n",
      "     46       37.2093       \u001b[32m28.0955\u001b[0m  0.0010  0.1287\n",
      "     46       38.9897       37.1374  0.0010  0.1202\n",
      "     48       37.2163       \u001b[32m25.5038\u001b[0m  0.0010  0.1241\n",
      "     45       \u001b[36m35.0783\u001b[0m       \u001b[32m26.3586\u001b[0m  0.0010  0.1221\n",
      "     48       \u001b[36m38.0823\u001b[0m       \u001b[32m27.1857\u001b[0m  0.0010  0.1202\n",
      "     49       36.8597       26.3541  0.0010  0.1001\n",
      "     49       \u001b[36m36.8294\u001b[0m       \u001b[32m27.1319\u001b[0m  0.0010  0.0925\n",
      "     47       \u001b[36m36.5991\u001b[0m       \u001b[32m27.8985\u001b[0m  0.0010  0.1356\n",
      "     47       \u001b[36m36.4298\u001b[0m       \u001b[32m36.1793\u001b[0m  0.0010  0.1299\n",
      "     46       \u001b[36m34.3219\u001b[0m       27.9024  0.0010  0.1229\n",
      "     50       37.9236       \u001b[32m26.1648\u001b[0m  0.0010  0.1064\n",
      "     50       \u001b[36m36.0201\u001b[0m       \u001b[32m25.4394\u001b[0m  0.0010  0.1362\n",
      "     48       \u001b[36m36.2699\u001b[0m       \u001b[32m27.4684\u001b[0m  0.0010  0.1764\n",
      "     48       37.1522       \u001b[32m35.2657\u001b[0m  0.0010  0.1950\n",
      "     47       35.1253       28.4085  0.0010  0.2018\n",
      "     51       37.5619       26.7771  0.0010  0.1705\n",
      "     51       \u001b[36m35.3760\u001b[0m       26.0422  0.0010  0.1695\n",
      "     49       \u001b[36m36.2328\u001b[0m       \u001b[32m27.1521\u001b[0m  0.0010  0.1480\n",
      "     49       \u001b[36m36.4063\u001b[0m       36.4799  0.0010  0.1279\n",
      "     48       34.5431       \u001b[32m25.5288\u001b[0m  0.0010  0.1284\n",
      "     52       \u001b[36m36.6347\u001b[0m       \u001b[32m25.4542\u001b[0m  0.0010  0.1237\n",
      "     52       \u001b[36m35.0426\u001b[0m       26.1865  0.0010  0.1069\n",
      "     50       \u001b[36m34.1611\u001b[0m       \u001b[32m26.8270\u001b[0m  0.0010  0.1248\n",
      "     49       \u001b[36m34.1345\u001b[0m       \u001b[32m25.4229\u001b[0m  0.0010  0.1212\n",
      "     50       36.7067       \u001b[32m34.6476\u001b[0m  0.0010  0.1386\n",
      "     53       \u001b[36m34.1691\u001b[0m       \u001b[32m24.7869\u001b[0m  0.0010  0.1050\n",
      "     53       37.3690       \u001b[32m25.1979\u001b[0m  0.0010  0.1151\n",
      "     51       36.3155       \u001b[32m26.5759\u001b[0m  0.0010  0.1268\n",
      "     50       34.4673       25.9811  0.0010  0.1126\n",
      "     51       \u001b[36m34.7760\u001b[0m       35.5971  0.0010  0.1192\n",
      "     54       \u001b[36m33.6724\u001b[0m       25.5052  0.0010  0.1056\n",
      "     54       \u001b[36m36.3117\u001b[0m       \u001b[32m24.8849\u001b[0m  0.0010  0.1224\n",
      "     51       \u001b[36m32.7339\u001b[0m       25.6995  0.0010  0.1219\n",
      "     55       33.7623       \u001b[32m24.4948\u001b[0m  0.0010  0.1009\n",
      "     52       35.1974       \u001b[32m26.1532\u001b[0m  0.0010  0.1337\n",
      "     52       \u001b[36m34.7131\u001b[0m       34.9375  0.0010  0.1245\n",
      "     55       \u001b[36m35.2822\u001b[0m       25.4940  0.0010  0.1236\n",
      "     53       \u001b[36m33.7645\u001b[0m       \u001b[32m25.9195\u001b[0m  0.0010  0.1103\n",
      "     52       34.1544       25.8666  0.0010  0.1224\n",
      "     53       \u001b[36m34.2219\u001b[0m       \u001b[32m34.1757\u001b[0m  0.0010  0.1126\n",
      "     56       33.7150       \u001b[32m23.5256\u001b[0m  0.0010  0.1197\n",
      "     56       36.2447       \u001b[32m23.7870\u001b[0m  0.0010  0.1234\n",
      "     54       34.4065       34.6929  0.0010  0.1094\n",
      "     53       \u001b[36m32.0328\u001b[0m       \u001b[32m24.4996\u001b[0m  0.0010  0.1224\n",
      "     54       \u001b[36m33.2192\u001b[0m       26.0414  0.0010  0.1382\n",
      "     57       \u001b[36m32.1846\u001b[0m       24.0430  0.0010  0.1366\n",
      "     57       36.2478       24.1340  0.0010  0.1145\n",
      "     55       34.7289       \u001b[32m33.4335\u001b[0m  0.0010  0.1333\n",
      "     54       32.6762       \u001b[32m24.4006\u001b[0m  0.0010  0.1248\n",
      "     55       33.7406       26.2311  0.0010  0.1194\n",
      "     58       33.3135       \u001b[32m23.2786\u001b[0m  0.0010  0.1166\n",
      "     58       35.4327       24.0859  0.0010  0.1216\n",
      "     56       34.4585       \u001b[32m32.9088\u001b[0m  0.0010  0.1219\n",
      "     56       33.3703       \u001b[32m25.6627\u001b[0m  0.0010  0.1196\n",
      "     59       33.6991       23.3800  0.0010  0.1188\n",
      "     55       \u001b[36m31.9150\u001b[0m       \u001b[32m23.7943\u001b[0m  0.0010  0.1383\n",
      "     59       \u001b[36m34.8841\u001b[0m       \u001b[32m23.5237\u001b[0m  0.0010  0.1268\n",
      "     57       34.8326       33.6973  0.0010  0.1267\n",
      "     56       33.1504       24.5953  0.0010  0.1180\n",
      "     57       \u001b[36m32.6068\u001b[0m       25.7151  0.0010  0.1405\n",
      "     60       32.8559       \u001b[32m23.1729\u001b[0m  0.0010  0.1416\n",
      "     60       \u001b[36m33.5940\u001b[0m       23.7690  0.0010  0.1172\n",
      "     58       \u001b[36m33.4153\u001b[0m       33.1142  0.0010  0.1323\n",
      "     57       32.0930       \u001b[32m23.6756\u001b[0m  0.0010  0.1320\n",
      "     58       33.8033       \u001b[32m25.4882\u001b[0m  0.0010  0.1358\n",
      "     61       \u001b[36m31.7904\u001b[0m       \u001b[32m22.5185\u001b[0m  0.0010  0.1330\n",
      "     61       34.0706       \u001b[32m23.2703\u001b[0m  0.0010  0.1321\n",
      "     58       32.4241       24.0840  0.0010  0.1204\n",
      "     59       \u001b[36m33.0540\u001b[0m       \u001b[32m32.0687\u001b[0m  0.0010  0.1352\n",
      "     59       \u001b[36m32.4331\u001b[0m       \u001b[32m24.9578\u001b[0m  0.0010  0.1239\n",
      "     62       32.5943       23.5424  0.0010  0.1336\n",
      "     62       34.6856       23.2851  0.0010  0.1234\n",
      "     60       34.2744       34.0130  0.0010  0.1141\n",
      "     59       \u001b[36m31.2789\u001b[0m       23.9331  0.0010  0.1248\n",
      "     60       32.7053       \u001b[32m24.5148\u001b[0m  0.0010  0.1286\n",
      "     63       32.2892       23.1129  0.0010  0.1208\n",
      "     63       34.0499       23.2734  0.0010  0.1218\n",
      "     61       \u001b[36m32.8050\u001b[0m       32.2107  0.0010  0.1275\n",
      "     60       32.2228       23.7412  0.0010  0.1401\n",
      "     61       32.7434       24.9906  0.0010  0.1320\n",
      "     64       \u001b[36m33.5898\u001b[0m       23.6718  0.0010  0.1218\n",
      "     64       \u001b[36m31.3817\u001b[0m       23.1932  0.0010  0.1309\n",
      "     62       32.9651       \u001b[32m31.9033\u001b[0m  0.0010  0.1156\n",
      "     61       32.2201       \u001b[32m22.6079\u001b[0m  0.0010  0.1317\n",
      "     65       \u001b[36m32.9448\u001b[0m       \u001b[32m21.8846\u001b[0m  0.0010  0.1228\n",
      "     65       31.5170       23.1583  0.0010  0.1227\n",
      "     62       \u001b[36m31.1620\u001b[0m       \u001b[32m24.3108\u001b[0m  0.0010  0.1268\n",
      "     63       33.0442       32.2599  0.0010  0.1225\n",
      "     62       31.9338       23.7689  0.0010  0.1214\n",
      "     66       33.4978       22.5581  0.0010  0.1186\n",
      "     63       31.6088       24.7645  0.0010  0.1262\n",
      "     64       33.5216       32.8141  0.0010  0.1174\n",
      "     67       33.0784       22.0063  0.0010  0.1055\n",
      "     64       31.6817       \u001b[32m23.9912\u001b[0m  0.0010  0.1183\n",
      "     63       \u001b[36m30.9202\u001b[0m       23.2332  0.0010  0.1374\n",
      "     65       \u001b[36m32.6761\u001b[0m       \u001b[32m31.7645\u001b[0m  0.0010  0.1258\n",
      "     68       \u001b[36m32.3818\u001b[0m       \u001b[32m21.8015\u001b[0m  0.0010  0.1057\n",
      "     64       \u001b[36m30.8429\u001b[0m       23.6800  0.0010  0.1204\n",
      "     65       32.1683       24.5393  0.0010  0.1262\n",
      "     66       \u001b[36m32.0590\u001b[0m       32.4743  0.0010  0.1214\n",
      "     69       \u001b[36m32.0964\u001b[0m       22.1764  0.0010  0.1130\n",
      "     65       \u001b[36m30.7157\u001b[0m       \u001b[32m22.4693\u001b[0m  0.0010  0.1173\n",
      "     66       \u001b[36m29.8233\u001b[0m       23.9974  0.0010  0.1259\n",
      "     67       \u001b[36m30.9287\u001b[0m       \u001b[32m31.2096\u001b[0m  0.0010  0.1182\n",
      "     70       32.4515       22.1281  0.0010  0.1206\n",
      "     66       31.0542       23.0065  0.0010  0.1143\n",
      "     67       31.7375       24.1527  0.0010  0.1065\n",
      "     68       31.7984       31.3802  0.0010  0.0950\n",
      "     71       33.0168       \u001b[32m21.3453\u001b[0m  0.0010  0.1023\n",
      "     67       \u001b[36m30.4042\u001b[0m       \u001b[32m22.2209\u001b[0m  0.0010  0.0935\n",
      "     68       31.0391       24.3785  0.0010  0.1138\n",
      "     72       \u001b[36m31.7530\u001b[0m       21.7231  0.0010  0.0907\n",
      "     69       \u001b[36m30.7453\u001b[0m       \u001b[32m29.8685\u001b[0m  0.0010  0.1282\n",
      "     68       30.7889       22.4316  0.0010  0.1243\n",
      "     69       \u001b[36m29.2939\u001b[0m       \u001b[32m23.6571\u001b[0m  0.0005  0.1099\n",
      "     73       \u001b[36m31.3351\u001b[0m       21.7095  0.0010  0.1148\n",
      "     70       31.3159       30.9384  0.0010  0.1047\n",
      "     70       30.2431       \u001b[32m23.5967\u001b[0m  0.0005  0.1104\n",
      "     69       \u001b[36m28.8295\u001b[0m       22.5269  0.0010  0.1285\n",
      "     74       32.1363       21.7417  0.0010  0.0996\n",
      "     71       31.8438       31.0833  0.0010  0.1111\n",
      "     70       29.9780       22.2217  0.0010  0.1112\n",
      "     71       29.5325       \u001b[32m23.0206\u001b[0m  0.0005  0.1211\n",
      "     75       32.4299       \u001b[32m21.1440\u001b[0m  0.0010  0.1132\n",
      "     72       \u001b[36m30.7012\u001b[0m       \u001b[32m29.7178\u001b[0m  0.0010  0.1197\n",
      "     72       29.3685       23.0347  0.0005  0.1032\n",
      "     71       29.9565       \u001b[32m21.6127\u001b[0m  0.0010  0.1080\n",
      "     76       32.1251       \u001b[32m20.9894\u001b[0m  0.0010  0.1207\n",
      "     73       31.6467       30.4714  0.0010  0.1270\n",
      "     73       30.4035       23.2147  0.0005  0.1245\n",
      "     72       29.9048       \u001b[32m21.0902\u001b[0m  0.0010  0.1272\n",
      "     77       31.5039       21.4379  0.0010  0.1357\n",
      "     74       \u001b[36m30.2819\u001b[0m       30.6585  0.0010  0.1259\n",
      "     74       30.4058       23.2659  0.0005  0.1827\n",
      "     73       29.7983       21.6238  0.0010  0.1969\n",
      "     78       \u001b[36m30.5588\u001b[0m       \u001b[32m20.8145\u001b[0m  0.0010  0.1722\n",
      "     75       \u001b[36m30.2101\u001b[0m       31.1467  0.0010  0.1770\n",
      "     75       30.1721       23.1268  0.0005  0.1298\n",
      "     74       \u001b[36m28.3325\u001b[0m       21.5136  0.0010  0.1280\n",
      "     79       31.6477       20.8705  0.0010  0.1164\n",
      "     76       30.5954       29.9851  0.0010  0.1191\n",
      "     76       29.7084       \u001b[32m22.7832\u001b[0m  0.0003  0.1309\n",
      "     80       \u001b[36m30.3137\u001b[0m       \u001b[32m19.6651\u001b[0m  0.0010  0.1078\n",
      "     75       29.6470       \u001b[32m19.8840\u001b[0m  0.0010  0.1438\n",
      "     77       \u001b[36m29.4113\u001b[0m       \u001b[32m29.3887\u001b[0m  0.0005  0.1282\n",
      "     77       29.4254       \u001b[32m22.6417\u001b[0m  0.0003  0.1219\n",
      "     81       30.8286       19.7462  0.0010  0.1170\n",
      "     76       29.4899       21.4153  0.0010  0.1072\n",
      "     78       30.7573       \u001b[32m29.3001\u001b[0m  0.0005  0.1069\n",
      "     82       30.7950       \u001b[32m19.3231\u001b[0m  0.0010  0.1050\n",
      "     78       \u001b[36m28.5292\u001b[0m       \u001b[32m22.5672\u001b[0m  0.0003  0.1111\n",
      "     77       29.2351       20.8575  0.0010  0.1156\n",
      "     79       29.4330       29.5895  0.0005  0.1069\n",
      "     83       \u001b[36m30.1404\u001b[0m       19.3949  0.0010  0.1076\n",
      "     79       29.8262       \u001b[32m22.4410\u001b[0m  0.0003  0.1137\n",
      "     78       28.6596       20.7817  0.0010  0.1229\n",
      "     80       \u001b[36m29.2918\u001b[0m       29.3764  0.0005  0.1033\n",
      "     84       \u001b[36m29.6454\u001b[0m       20.0265  0.0010  0.1034\n",
      "     80       29.9074       22.4956  0.0003  0.1146\n",
      "     79       28.8810       20.1672  0.0010  0.1178\n",
      "     81       29.4994       \u001b[32m28.7128\u001b[0m  0.0005  0.1217\n",
      "     85       31.2470       \u001b[32m19.1502\u001b[0m  0.0010  0.1066\n",
      "     81       29.1046       \u001b[32m22.3300\u001b[0m  0.0003  0.1240\n",
      "     82       \u001b[36m29.2813\u001b[0m       29.1769  0.0005  0.1069\n",
      "     86       \u001b[36m29.4958\u001b[0m       19.5181  0.0010  0.1078\n",
      "     82       29.3503       22.4517  0.0003  0.1115\n",
      "     83       29.7412       29.1517  0.0005  0.1196\n",
      "     87       30.0869       19.5325  0.0010  0.1082\n",
      "     83       29.2044       22.3788  0.0003  0.0985\n",
      "     84       \u001b[36m29.1987\u001b[0m       29.8007  0.0005  0.1111\n",
      "     88       \u001b[36m28.7996\u001b[0m       19.3950  0.0010  0.1153\n",
      "     84       29.3157       22.4717  0.0003  0.1219\n",
      "     85       \u001b[36m28.9022\u001b[0m       \u001b[32m27.7339\u001b[0m  0.0005  0.1063\n",
      "     89       29.8629       19.9071  0.0010  0.1112\n",
      "     85       29.1183       22.5051  0.0003  0.1154\n",
      "     86       \u001b[36m28.0455\u001b[0m       28.4562  0.0005  0.1252\n",
      "     87       28.7716       28.0352  0.0005  0.0876\n",
      "     88       28.2712       28.8230  0.0005  0.0777\n",
      "     89       \u001b[36m27.8920\u001b[0m       28.5399  0.0005  0.1183\n",
      "RMSE for each folder: [5.47852154 5.05243502 5.76676024 4.31781651 4.51542204]\n",
      "RMSE mean: 5.026191070435441\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#Small nn\n",
    "class Cov_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.s = nn.Sequential(\n",
    "          nn.Linear(36, 128),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.3),\n",
    "          nn.Linear(128, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.3),\n",
    "          nn.Linear(64, 51)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.s(x)\n",
    "\n",
    "net_nn2 = NeuralNetRegressor(\n",
    "    module      = Cov_nn,\n",
    "    max_epochs  = 200,\n",
    "    lr          = 1e-3,\n",
    "    batch_size  = 64,\n",
    "    optimizer   = torch.optim.Adam,\n",
    "    callbacks=[('earlystop', EarlyStopping('valid_loss', patience=5)), # Stop if validation loss doesn't improve for 5 epochs \n",
    "                    ('lr_sched', LRScheduler(\n",
    "           policy=torch.optim.lr_scheduler.ReduceLROnPlateau, # Halve LR if validation loss stalls for 3 epochs\n",
    "           monitor='valid_loss',\n",
    "           patience=3, factor=0.5))]\n",
    ")\n",
    "\n",
    "\n",
    "pipe_fusion = Pipeline([\n",
    "    ('cov',   Covariances(estimator='oas')),   \n",
    "    ('ts',    TangentSpace()),                \n",
    "    ('scale', StandardScaler()),               \n",
    "    ('cast',  FunctionTransformer(lambda X: X.astype(np.float32), validate=False)), # cast to float32 for PyTorch compatibility\n",
    "    ('nn',   net_nn2)                          \n",
    "])\n",
    "\n",
    "x_covnn = X_g_train_reshape.astype('float32')\n",
    "\n",
    "cross_validation_with_scores(x_covnn,y,groups,pipe_fusion,logo,rmse_scorer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2f89932-867f-4c54-9a38-d64b949fe003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      lr     dur\n",
      "-------  ------------  ------------  ------  ------\n",
      "      1      \u001b[36m435.8468\u001b[0m      \u001b[32m309.0137\u001b[0m  0.0010  0.1019\n",
      "      2      \u001b[36m210.2736\u001b[0m      \u001b[32m143.8805\u001b[0m  0.0010  0.1185\n",
      "      3      \u001b[36m146.5507\u001b[0m      \u001b[32m125.2401\u001b[0m  0.0010  0.0917\n",
      "      4      \u001b[36m125.4712\u001b[0m      \u001b[32m112.3829\u001b[0m  0.0010  0.0909\n",
      "      5      \u001b[36m110.7206\u001b[0m      \u001b[32m102.0065\u001b[0m  0.0010  0.0888\n",
      "      6       \u001b[36m98.7314\u001b[0m       \u001b[32m91.7140\u001b[0m  0.0010  0.0878\n",
      "      7       \u001b[36m92.4977\u001b[0m       \u001b[32m84.9626\u001b[0m  0.0010  0.0951\n",
      "      8       \u001b[36m86.3409\u001b[0m       \u001b[32m78.2512\u001b[0m  0.0010  0.0900\n",
      "      9       \u001b[36m79.5099\u001b[0m       \u001b[32m74.5852\u001b[0m  0.0010  0.0980\n",
      "     10       \u001b[36m76.2653\u001b[0m       \u001b[32m69.7801\u001b[0m  0.0010  0.0866\n",
      "     11       \u001b[36m73.8756\u001b[0m       \u001b[32m66.8241\u001b[0m  0.0010  0.0904\n",
      "     12       \u001b[36m69.1183\u001b[0m       \u001b[32m62.6284\u001b[0m  0.0010  0.1013\n",
      "     13       \u001b[36m67.3028\u001b[0m       \u001b[32m61.8715\u001b[0m  0.0010  0.0994\n",
      "     14       \u001b[36m63.4070\u001b[0m       \u001b[32m59.0534\u001b[0m  0.0010  0.0981\n",
      "     15       \u001b[36m60.8692\u001b[0m       \u001b[32m57.3412\u001b[0m  0.0010  0.1078\n",
      "     16       \u001b[36m59.7900\u001b[0m       \u001b[32m55.1862\u001b[0m  0.0010  0.1077\n",
      "     17       \u001b[36m58.4047\u001b[0m       \u001b[32m54.0506\u001b[0m  0.0010  0.1005\n",
      "     18       \u001b[36m57.2950\u001b[0m       \u001b[32m51.6011\u001b[0m  0.0010  0.0941\n",
      "     19       \u001b[36m56.0161\u001b[0m       \u001b[32m51.0655\u001b[0m  0.0010  0.0955\n",
      "     20       \u001b[36m54.8469\u001b[0m       51.4469  0.0010  0.0944\n",
      "     21       \u001b[36m52.1275\u001b[0m       \u001b[32m47.6369\u001b[0m  0.0010  0.0912\n",
      "     22       \u001b[36m51.3096\u001b[0m       \u001b[32m47.4827\u001b[0m  0.0010  0.0986\n",
      "     23       \u001b[36m50.7243\u001b[0m       \u001b[32m45.1423\u001b[0m  0.0010  0.0987\n",
      "     24       \u001b[36m49.8320\u001b[0m       45.1607  0.0010  0.0981\n",
      "     25       \u001b[36m49.2729\u001b[0m       \u001b[32m44.2114\u001b[0m  0.0010  0.0935\n",
      "     26       \u001b[36m48.7296\u001b[0m       \u001b[32m42.3776\u001b[0m  0.0010  0.0969\n",
      "     27       \u001b[36m46.4424\u001b[0m       \u001b[32m42.2036\u001b[0m  0.0010  0.0969\n",
      "     28       \u001b[36m45.9215\u001b[0m       \u001b[32m40.8980\u001b[0m  0.0010  0.1109\n",
      "     29       45.9253       \u001b[32m38.7985\u001b[0m  0.0010  0.1197\n",
      "     30       \u001b[36m45.2882\u001b[0m       39.2329  0.0010  0.1111\n",
      "     31       \u001b[36m43.3653\u001b[0m       \u001b[32m37.2662\u001b[0m  0.0010  0.1056\n",
      "     32       44.1019       \u001b[32m37.0191\u001b[0m  0.0010  0.0998\n",
      "     33       \u001b[36m42.2306\u001b[0m       \u001b[32m36.8174\u001b[0m  0.0010  0.0923\n",
      "     34       43.0998       38.2588  0.0010  0.0984\n",
      "     35       \u001b[36m40.7253\u001b[0m       \u001b[32m35.2753\u001b[0m  0.0010  0.0974\n",
      "     36       41.0186       \u001b[32m34.1370\u001b[0m  0.0010  0.1005\n",
      "     37       41.9123       \u001b[32m33.3618\u001b[0m  0.0010  0.0992\n",
      "     38       \u001b[36m39.3858\u001b[0m       \u001b[32m32.3382\u001b[0m  0.0010  0.0948\n",
      "     39       40.1516       32.8185  0.0010  0.0977\n",
      "     40       \u001b[36m38.3046\u001b[0m       \u001b[32m31.7478\u001b[0m  0.0010  0.0921\n",
      "     41       39.0705       31.8872  0.0010  0.0930\n",
      "     42       38.4382       \u001b[32m31.5116\u001b[0m  0.0010  0.1623\n",
      "     43       38.4650       31.7797  0.0010  0.0986\n",
      "     44       \u001b[36m37.9108\u001b[0m       \u001b[32m30.5892\u001b[0m  0.0010  0.1121\n",
      "     45       \u001b[36m36.6699\u001b[0m       \u001b[32m30.4325\u001b[0m  0.0010  0.1045\n",
      "     46       \u001b[36m36.5713\u001b[0m       \u001b[32m29.7890\u001b[0m  0.0010  0.0967\n",
      "     47       37.1164       \u001b[32m28.4586\u001b[0m  0.0010  0.0941\n",
      "     48       \u001b[36m35.8856\u001b[0m       28.7832  0.0010  0.0959\n",
      "     49       36.1119       28.9526  0.0010  0.0994\n",
      "     50       \u001b[36m34.9706\u001b[0m       \u001b[32m27.4789\u001b[0m  0.0010  0.0890\n",
      "     51       35.9091       28.3693  0.0010  0.0953\n",
      "     52       35.3578       \u001b[32m27.3177\u001b[0m  0.0010  0.0979\n",
      "     53       \u001b[36m34.4337\u001b[0m       \u001b[32m27.1210\u001b[0m  0.0010  0.0927\n",
      "     54       \u001b[36m34.2117\u001b[0m       \u001b[32m27.0332\u001b[0m  0.0010  0.1015\n",
      "     55       34.3497       \u001b[32m26.8764\u001b[0m  0.0010  0.1011\n",
      "     56       \u001b[36m33.6435\u001b[0m       \u001b[32m25.5796\u001b[0m  0.0010  0.0967\n",
      "     57       34.1516       25.6029  0.0010  0.0957\n",
      "     58       \u001b[36m33.4111\u001b[0m       \u001b[32m25.2221\u001b[0m  0.0010  0.0993\n",
      "     59       \u001b[36m31.7469\u001b[0m       \u001b[32m24.7413\u001b[0m  0.0010  0.0981\n",
      "     60       32.4463       25.7240  0.0010  0.0953\n",
      "     61       32.1121       25.2315  0.0010  0.0914\n",
      "     62       32.9761       \u001b[32m24.6264\u001b[0m  0.0010  0.0957\n",
      "     63       31.8161       24.7484  0.0010  0.0910\n",
      "     64       \u001b[36m31.7380\u001b[0m       \u001b[32m24.2755\u001b[0m  0.0010  0.0999\n",
      "     65       \u001b[36m31.7237\u001b[0m       \u001b[32m23.7571\u001b[0m  0.0010  0.1066\n",
      "     66       \u001b[36m31.6496\u001b[0m       24.2346  0.0010  0.0907\n",
      "     67       31.6625       24.0262  0.0010  0.1011\n",
      "     68       \u001b[36m30.4979\u001b[0m       24.3928  0.0010  0.0942\n",
      "     69       31.7715       23.7729  0.0010  0.0963\n",
      "     70       \u001b[36m29.9702\u001b[0m       \u001b[32m22.5750\u001b[0m  0.0005  0.0882\n",
      "     71       30.4951       22.8133  0.0005  0.0959\n",
      "     72       30.3358       23.0016  0.0005  0.0941\n",
      "     73       30.3067       23.4027  0.0005  0.0890\n",
      "     74       \u001b[36m29.9654\u001b[0m       23.3874  0.0005  0.0978\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe_fusion.fit(x_covnn, y)\n",
    "\n",
    "history = pipe_fusion.named_steps['nn'].history\n",
    "\n",
    "epochs = history[:, 'epoch']\n",
    "train_loss = history[:, 'train_loss']\n",
    "valid_loss = history[:, 'valid_loss']\n",
    "\n",
    "plt.plot(epochs, train_loss, label='Train loss')\n",
    "plt.plot(epochs, valid_loss, label='Valid loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Train/Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ad26a5e-f3e6-4a07-aae2-23535b5a84a0",
   "metadata": {},
   "source": [
    "| Method                                   | RMSE moyen |\n",
    "|------------------------------------------|-----------:|\n",
    "| Basic Lasso                              |      21.26 |\n",
    "| Baseline approach                        |        â€“   |\n",
    "| Covariance matrices + Lasso              |       8.19 |\n",
    "| Covariance matrices + Neural Network     |       5.02 |\n",
    "| Convolutional Neural Network             |       4.87 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "When we compare the progression of our models, we see that incorporating covariance matrices into a simple Lasso regressor brings the rmse down about 62 % over the basic Lasso. \n",
    "\n",
    "...\n",
    "\n",
    "Moving on to a small neural network trained on those 36 tangentâ€space features further reduces the error to 5.02, which represents a 39 % drop. Finally, the cnn achieves the lowest rmse of 4.87, a modest 3 % gain over the covariance nn hybrid.\n",
    "\n",
    "That last 3 % improvement, however, comes at a cost, the cnn is significantly more complex to train and deploy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e1878-049b-4342-ad98-3c20afa1110e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
